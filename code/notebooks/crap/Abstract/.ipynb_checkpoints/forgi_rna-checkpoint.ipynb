{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ikea/GraphLearn/GraphLearn_examples/Abstract\r\n"
     ]
    }
   ],
   "source": [
    "from eden.util import configure_logging\n",
    "import logging\n",
    "configure_logging(logging.getLogger(),verbosity=1)\n",
    "%matplotlib inline\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "GET RNA DATA\n",
    "'''\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import itertools\n",
    "\n",
    "def rfam_uri(family_id):\n",
    "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "def rfam_uri(family_id):\n",
    "    return '%s.fa'%(family_id)\n",
    " \n",
    "def get_graphss(rfam_id = '../toolsdata/RF00005'):\n",
    "    return fasta_to_sequence(rfam_uri(rfam_id))\n",
    "\n",
    "def get_graphs(rfam_id = '../toolsdata/RF00005', count=100):\n",
    "    for a,b in itertools.islice( get_graphss(rfam_id),count):\n",
    "        yield b\n",
    "\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "def get_sequences(size=9999):\n",
    "    sequences = itertools.islice( fasta_to_sequence(\"../toolsdata/RF00005.fa\"), size)\n",
    "    return [ b for (a,b) in sequences ]\n",
    "\n",
    "def get_sequences_with_names(size=9999):\n",
    "    sequences = itertools.islice( fasta_to_sequence(\"../toolsdata/RF00005.fa\"), size)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''TESTING EXTRACTION AND GRAPHMANAGER'''\n",
    "from graphlearn.utils import draw\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "from eden.graph import Vectorizer\n",
    "\n",
    "vectorizer=Vectorizer()\n",
    "pp=rna.PreProcessor(ignore_inserts=True)\n",
    "pp.fit(get_sequences_with_names(),vectorizer)\n",
    "graphmanagers=pp.transform(get_sequences()[:20])\n",
    "\n",
    "print 'DEMONSTRATING GRAPH MANAGER'\n",
    "\n",
    "for i in [4]:\n",
    "    print 'grammar example %d' % i\n",
    "    gm=graphmanagers[i]\n",
    "    g=gm.graph(nested=True)\n",
    "    #print g.nodes(data=True)\n",
    "    #g.node[0].pop('weight')\n",
    "    # jump because we do the thesis now\n",
    "    #vec=vectorizer.transform_single(g)\n",
    "    #def graph(self, nested=True,fcorrect=False,base_only=False):\n",
    "    #draw.graphlearn([gm.graph(nested=False,fcorrect=True,base_only=True),gm.abstract_graph(),gm.base_graph()], size = 15,vertex_label = 'label',contract=True)\n",
    "    \n",
    "    draw.graphlearn(gm.graph(nested=False,fcorrect=True,base_only=True), size = 15,vertex_label = 'label',contract=True)\n",
    "    g=gm.graph(nested=False,fcorrect=True,base_only=True)\n",
    "    #draw.graphlearn([gm.base_graph()], size = 15,vertex_label = 'label',contract=True)\n",
    "    \n",
    "    print gm.sequence\n",
    "    print gm.structure\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "print 'DEMONSTRATING EXTRACTION'  \n",
    "#prepare\n",
    "radius_list=[0,2]\n",
    "thickness_list=[2,4]\n",
    "base_thickness_list=[2]\n",
    "f=lambda x, y: True\n",
    "d={'radius_list':radius_list,\n",
    "    'thickness_list':thickness_list,\n",
    "    'hash_bitmask':2**20-1,\n",
    "    'node_filter': f}\n",
    "\n",
    "\n",
    "#draw.graphlearn([gm.abstract_graph(),gm.base_graph()], size = 15,vertex_label = 'id',contract=True)\n",
    "cips=gm.all_core_interface_pairs(**d)\n",
    "for li, ciplist in enumerate(cips):\n",
    "    for entry, cip in enumerate(ciplist):\n",
    "        continue\n",
    "        z='list: %d ; entry: %d' % (li,entry)\n",
    "        #cip.graph.graph['info']=z\n",
    "        draw.graphlearn([cip.graph,cip.abstract_view], size=4, contract=True) \n",
    "cipz=[cips[2][3],cips[1][3],cips[1][2]]\n",
    "graphz=[[c.graph,c.abstract_view] for c in cipz]\n",
    "    \n",
    "#g=gm.graph(nested=False)\n",
    "#print 'test', g.nodes(data=True)[0][1]\n",
    "\n",
    "#for graphpair in graphz:\n",
    "#    draw.graphlearn(graphpair, size=10,font_size=36,# secondary_vertex_label='ID',\n",
    "#                   colormap='Paired', invert_colormap=False,node_border=0.5,contract=True,\n",
    "#                   vertex_alpha=0.5, node_size=1900)\n",
    "    \n",
    "    \n",
    "    \n",
    "minor = gm.abstract_graph()\n",
    "minorcip = graphz[0][1]\n",
    "\n",
    "def wire(g,nset=[]):\n",
    "    for n in nset:\n",
    "        z=str(n)\n",
    "        g.add_edge(\"+\"+z,\"-\"+z,nesting=True,weight='.2',len=2)\n",
    "        \n",
    "draw.graphlearn([minor,minorcip], size=10,font_size=36,# secondary_vertex_label='ID',\n",
    "                   colormap='Paired', invert_colormap=False,node_border=0.5,contract=True,\n",
    "                   vertex_alpha=0.5, node_size=1900)\n",
    "#[minor,minorcip]\n",
    "\n",
    "def colorize(g,c1=[],c2=[],c3=[],label='mycolors'):\n",
    "    for n,d in g.nodes(data=True):\n",
    "        if n in c1:\n",
    "            d[label]='#C88A68' #reddish\n",
    "        elif n in c2: \n",
    "            d[label]='#FAF4B0' # yellow\n",
    "        elif n in c3:\n",
    "            d[label]='#C9BC24' # dark yellow\n",
    "        else:\n",
    "            d[label]='#C1DDEB' # default color -- blueish\n",
    "\n",
    "colorize(minor,c1=[2,3],c2=[5,9,10,0],c3=[])\n",
    "colorize(minorcip,c1=[2,3],c2=[5,9,10,0],c3=[])\n",
    "#g3=draw.cip_to_drawable_graph(cips=[cips[2][3]], graphs=[minor])\n",
    "\n",
    "draw.graphlearn([minor,minorcip], size=10,font_size=36, #secondary_vertex_label='id',\n",
    "                    contract=True,\n",
    "                   colormap='Paired', invert_colormap=False,node_border=0.5,vertex_color='mycolors',\n",
    "                   vertex_alpha=0.5, node_size=1900)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 4.17 s, total: 2min 6s\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "learning a grammar\n",
    "'''\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "import graphlearn.estimator as estimator\n",
    "# not really needed since after refolding we get an RNA\n",
    "#feasibility=Checker()\n",
    "#feasibility.checklist.append(rna.is_rna)\n",
    "graphs = get_sequences_with_names(size=200)\n",
    "\n",
    "\n",
    "\n",
    "estimator=estimator.Wrapper( nu=.33, cv=2, n_jobs=-1)\n",
    "\n",
    "sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                            thickness_list=[2], \n",
    "                            min_cip_count=1, \n",
    "                            min_interface_count=2, \n",
    "                            preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                            postprocessor=rna.PostProcessor(),\n",
    "                            estimator=estimator\n",
    "                            #feasibility_checker=feasibility\n",
    "                           )\n",
    "sampler.fit(graphs,grammar_n_jobs=1,grammar_batch_size=1)\n",
    "sampler.save('../tmp/rna_ubergrammar.ge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#draw production rules\n",
    "draw.draw_grammar(sampler.lsgg.productions,n_productions=5,n_graphs_per_production=5,\n",
    "                     n_graphs_per_line=6, size=10, contract=False,\n",
    "                     colormap='Paired', invert_colormap=False,node_border=1,\n",
    "                     vertex_alpha=0.6, edge_alpha=0.5, node_size=250, abstract_interface=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph id: 66\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'nodes_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b284819da5a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu\"'''\\nRna sampling\\n'''\\nimport os\\nos.nice(19)\\nimport graphlearn.utils.draw as draw\\nimport graphlearn.abstract_graphs.RNA as rna\\nfrom graphlearn.graphlearn import Sampler as GLS\\nimport itertools\\n#sampler=rna.AbstractSampler(radius_list=[0,1],thickness_list=[2], min_cip_count=1, min_interface_count=2, preprocessor=rna.PreProcessor(), postprocessor=rna.PostProcessor())\\n#sampler.load('tmp/rna_ubergrammar.ge')\\n\\n\\ngraphs = get_graphs()\\nid_start=66\\nid_end=id_start+12\\ngraphs = itertools.islice(graphs,id_start,id_end)\\nn_steps=200\\n\\ngraphs = sampler.sample(graphs,\\n                        n_samples=3,\\n                        batch_size=1,\\n                        n_steps=n_steps,\\n                        n_jobs=4,\\n                        quick_skip_orig_cip=True,\\n                        probabilistic_core_choice=True,\\n                        burnin=0,\\n                        improving_threshold=0.7,\\n                        improving_linear_start=0.2,\\n                        #max_size_diff=20,\\n                        accept_min_similarity=0.65,\\n                        select_cip_max_tries=30,\\n                        keep_duplicates=False,\\n                        include_seed=True,\\n                        backtrack=10,\\n                        monitor=True)\\n\\n\\nfrom eden.modifier.graph.vertex_attributes import colorize   \\nscores=[]\\nsequences=[]\\nids=range(id_start,id_end)\\nfor i,graphlist in enumerate(graphs):\\n    print 'Graph id: %d'%(ids[i])\\n    scores.append(sampler.monitors[i].sampling_info['score_history'])\\n    \\n    sequences.append(sampler.monitors[i].sampling_info['notes'])\\n    \\n    path_graphs = colorize(graphlist,\\n                           output_attribute = 'color_level', \\n                           labels = ['A','U','G','C'])\\n    path_graphs= list(path_graphs)\\n    draw.graphlearn(path_graphs,\\n                           n_graphs_per_line=3, size=20, \\n                           colormap='Paired', invert_colormap=False,node_border=0.5, vertex_color='color_level',\\n                           vertex_alpha=0.5, edge_alpha=0.7, node_size=450,edge_label='label' )\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ikea/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ikea/.local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/ikea/.local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ikea/.local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/ikea/EDeN/eden/modifier/graph/vertex_attributes.pyc\u001b[0m in \u001b[0;36mcolorize\u001b[1;34m(graph_list, output_attribute, labels, mode)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m# iterate over nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"3D\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_attribute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolor_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'nodes_iter'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Rna sampling\n",
    "'''\n",
    "import os\n",
    "os.nice(19)\n",
    "import graphlearn.utils.draw as draw\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "#sampler=rna.AbstractSampler(radius_list=[0,1],thickness_list=[2], min_cip_count=1, min_interface_count=2, preprocessor=rna.PreProcessor(), postprocessor=rna.PostProcessor())\n",
    "#sampler.load('tmp/rna_ubergrammar.ge')\n",
    "\n",
    "\n",
    "graphs = get_graphs()\n",
    "id_start=66\n",
    "id_end=id_start+12\n",
    "graphs = itertools.islice(graphs,id_start,id_end)\n",
    "n_steps=200\n",
    "\n",
    "graphs = sampler.sample(graphs,\n",
    "                        n_samples=3,\n",
    "                        batch_size=1,\n",
    "                        n_steps=n_steps,\n",
    "                        n_jobs=4,\n",
    "                        quick_skip_orig_cip=True,\n",
    "                        probabilistic_core_choice=True,\n",
    "                        burnin=0,\n",
    "                        improving_threshold=0.7,\n",
    "                        improving_linear_start=0.2,\n",
    "                        #max_size_diff=20,\n",
    "                        accept_min_similarity=0.65,\n",
    "                        select_cip_max_tries=30,\n",
    "                        keep_duplicates=False,\n",
    "                        include_seed=True,\n",
    "                        backtrack=10,\n",
    "                        monitor=True)\n",
    "\n",
    "\n",
    "from eden.modifier.graph.vertex_attributes import colorize   \n",
    "scores=[]\n",
    "sequences=[]\n",
    "ids=range(id_start,id_end)\n",
    "for i,graphlist in enumerate(graphs):\n",
    "    print 'Graph id: %d'%(ids[i])\n",
    "    scores.append(sampler.monitors[i].sampling_info['score_history'])\n",
    "    \n",
    "    sequences.append(sampler.monitors[i].sampling_info['notes'])\n",
    "    \n",
    "    #path_graphs = colorize(graphlist, output_attribute = 'color_level',labels = ['A','U','G','C'])\n",
    "    #path_graphs= list(path_graphs)\n",
    "    \n",
    "    draw.graphlearn(graphlist,\n",
    "                           n_graphs_per_line=3, size=20, \n",
    "                           colormap='Paired', invert_colormap=False,node_border=0.5, vertex_color='color_level',\n",
    "                           vertex_alpha=0.5, edge_alpha=0.7, node_size=450,edge_label='label' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%matplotlib inline\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "step=1\n",
    "num_graphs_per_plot=3\n",
    "num_plots=np.ceil([len(scores)/num_graphs_per_plot])\n",
    "for i in range(num_plots):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for j,score in enumerate(scores[i*num_graphs_per_plot:i*num_graphs_per_plot+num_graphs_per_plot]):\n",
    "        data = list(islice(score,None, None, step))\n",
    "        plt.plot(data, label='graph %d'%(j+i*num_graphs_per_plot+id_start))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()\n",
    "    \n",
    "'''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "draw the score history for each of the graphs\n",
    "'''\n",
    "colors=['b','g','r','c','m','y','k','w']\n",
    "\n",
    "%matplotlib inline\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "step=1\n",
    "num_graphs_per_plot=2\n",
    "num_plots=np.ceil([len(scores)/num_graphs_per_plot])\n",
    "for i in range(num_plots):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for j,score in enumerate(scores[i*num_graphs_per_plot:i*num_graphs_per_plot+num_graphs_per_plot]):\n",
    "        data = list(islice(score,None, None, step))\n",
    "        plt.plot(data,ls='-',color=colors[j], label='graph %d'%(j+i*num_graphs_per_plot+id_start))\n",
    "\n",
    "        # okok now we need to add the infernal evaluation\n",
    "        seqs=sequences[i*num_graphs_per_plot+j]\n",
    "        seqs=seqs.split('n')\n",
    "        \n",
    "        # SEQUENCES STILL CONTAIN F, ALSO THERE ARE ERRORMESSAGES AT THE END OF INFO\n",
    "        #seqs=seqs[:-1]\n",
    "    \n",
    "        #print seqs\n",
    "        data2= rna.infernal_checker(seqs,cmfile='../rf00005.cm')\n",
    "        #print data2,seqs\n",
    "        plt.plot(data2,ls='--',color=colors[j], label='infernal %d'%(j+i*num_graphs_per_plot+id_start))\n",
    "    plt.plot([0.29]*len(data2),ls='-.',color='r', label='significance') #| '-' | '--' | '-.' | ':' | 'None' | ' ' |\n",
    "    plt.legend(loc='lower left',framealpha=0.5)\n",
    "    plt.grid()\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "import graphlearn.utils.draw as draw\n",
    "\n",
    "#faillist=[0,2,4,5]\n",
    "# for every failed graph\n",
    "\n",
    "runs=[]\n",
    "for i,mon in enumerate(sampler.monitors):\n",
    "    lastgraph=None\n",
    "    run=[]\n",
    "    for t,graphs in mon.format(start=0):\n",
    "        if lastgraph!=None:\n",
    "            v=sampler.vectorizer.similarity([graphs[0].copy()],lastgraph).next()\n",
    "            \n",
    "            run.append(v)\n",
    "        lastgraph=graphs[0]\n",
    "    runs.append(run)\n",
    "import numpy\n",
    "for run in runs:\n",
    "    a= numpy.array(run)\n",
    "    print numpy.mean(a, axis=0),' ',numpy.std(a, axis=0)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    if len(mon.content) < 80:\n",
    "        for t,graphs in mon.format(start=0):\n",
    "            # print relevant info\n",
    "\n",
    "            draw.graphlearn(graphs,size=6,node_border=.5)\n",
    "\n",
    "            lastgraph=graphs[0]\n",
    "            \n",
    "        print \"#\"*80\n",
    "        print \"#\"*80\n",
    "        break\n",
    "            #print monentry['graphwrapper'].sequence\n",
    "            #print monentry['graphwrapper'].structure\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "In [18]: arr =\n",
    "\n",
    "In [20]: numpy.mean(arr, axis=0)\n",
    "Out[20]: \n",
    "array([ 0.7       ,  2.2       ,  1.8       ,  2.13333333,  3.36666667,\n",
    "        5.1       ])\n",
    "\n",
    "In [21]: numpy.std(arr, axis=0)\n",
    "Out[21]: \n",
    "array([ 0.45460606,  1.29614814,  1.37355985,  1.50628314,  1.15566239,\n",
    "        1.2083046 ])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print run\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "import graphlearn.utils.draw as draw\n",
    "from eden.graph import Vectorizer\n",
    "\n",
    "v=Vectorizer()\n",
    "def getpathgraph(labels):\n",
    "    nlabels= len(labels)\n",
    "    G=nx.path_graph(nlabels)\n",
    "    for e in range(nlabels):\n",
    "        G.node[e]['label']=labels[e]\n",
    "    for e in range(nlabels-1):\n",
    "        G.edge[e][e+1]['label']='.'\n",
    "    return G\n",
    "\n",
    "g=getpathgraph(\"ABC\")\n",
    "\n",
    "g= v._edge_to_vertex_transform(g)\n",
    "\n",
    "draw.graphlearn_draw(g,contract=False,show_direction=True)\n",
    "\n",
    "g2=nx.DiGraph(g)\n",
    "#draw.display(g2,contract=False,vertex_label='id')\n",
    "\n",
    "for n,d in g2.nodes(data=True):\n",
    "    if 'edge' in d:\n",
    "        if d['label']=='.':\n",
    "            ns=g2.neighbors(n)\n",
    "            g2.remove_edge(ns[1],n)\n",
    "            g2.remove_edge(n,ns[0])\n",
    "          \n",
    "       \n",
    "#g2 = g2.to_undirected()\n",
    "draw.graphlearn(g2,contract=False,vertex_label='id',show_direction=True)\n",
    "g2.edges()\n",
    "for n in g2.nodes():\n",
    "    print n,g2.neighbors(n)\n",
    "print isinstance(g2, nx.DiGraph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2.edges(0,data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asd = g2.subgraph(range(2)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    def __init__(self,a=123):\n",
    "        self.a=a\n",
    "        \n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self,b=122):\n",
    "        super(B,self).__init__(b)\n",
    "        \n",
    "        \n",
    "\n",
    "class C(A):\n",
    "    def __init__(self,c=121):\n",
    "        super(C,self).__init__(c)\n",
    "        \n",
    "        \n",
    "c=C()\n",
    "c.a\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testin cycle stuff\n",
    "import networkx as nx\n",
    "import graphlearn.utils.draw as draw\n",
    "import graphlearn.feasibility as feas\n",
    "from eden.graph import Vectorizer\n",
    "v=Vectorizer()\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def find_all_cycles(G, source=None, cycle_length_limit=None):\n",
    "    \"\"\"forked from networkx dfs_edges function. Assumes nodes are integers, or at least\n",
    "    types which work with min() and > .\"\"\"\n",
    "    if source is None:\n",
    "        # produce edges for all components\n",
    "        nodes=[i[0] for i in nx.connected_components(G)]\n",
    "    else:\n",
    "        # produce edges for components with source\n",
    "        nodes=[source]\n",
    "    # extra variables for cycle detection:\n",
    "    cycle_stack = []\n",
    "    output_cycles = set()\n",
    "    \n",
    "    def get_hashable_cycle(cycle):\n",
    "        \"\"\"cycle as a tuple in a deterministic order.\"\"\"\n",
    "        m = min(cycle)\n",
    "        mi = cycle.index(m)\n",
    "        mi_plus_1 = mi + 1 if mi < len(cycle) - 1 else 0\n",
    "        if cycle[mi-1] > cycle[mi_plus_1]:\n",
    "            result = cycle[mi:] + cycle[:mi]\n",
    "        else:\n",
    "            result = list(reversed(cycle[:mi_plus_1])) + list(reversed(cycle[mi_plus_1:]))\n",
    "        return tuple(result)\n",
    "    \n",
    "    for start in nodes:\n",
    "        if start in cycle_stack:\n",
    "            continue\n",
    "        cycle_stack.append(start)\n",
    "        \n",
    "        stack = [(start,iter(G[start]))]\n",
    "        while stack:\n",
    "            parent,children = stack[-1]\n",
    "            try:\n",
    "                child = next(children)\n",
    "                \n",
    "                if child not in cycle_stack:\n",
    "                    cycle_stack.append(child)\n",
    "                    stack.append((child,iter(G[child])))\n",
    "                else:\n",
    "                    i = cycle_stack.index(child)\n",
    "                    if i < len(cycle_stack) - 2: \n",
    "                      output_cycles.add(get_hashable_cycle(cycle_stack[i:]))\n",
    "                \n",
    "            except StopIteration:\n",
    "                stack.pop()\n",
    "                cycle_stack.pop()\n",
    "    \n",
    "    return [list(i) for i in output_cycles]\n",
    "\n",
    "\n",
    "def getpathgraph(labels):\n",
    "    nlabels= len(labels)\n",
    "    G=nx.path_graph(nlabels)\n",
    "    for e in range(nlabels):\n",
    "        G.node[e]['label']=labels[e]\n",
    "    for e in range(nlabels-1):\n",
    "        G.edge[e][e+1]['label']='.'\n",
    "    return G\n",
    "\n",
    "#g=getpathgraph(\"ABC\")\n",
    "\n",
    "#g= v._edge_to_vertex_transform(g)\n",
    "\n",
    "#draw.graphlearn_draw(g,contract=False,show_direction=True)\n",
    "\n",
    "\n",
    "#draw.display(g2,contract=False,vertex_label='id')\n",
    "\n",
    "g=nx.cycle_graph(10)\n",
    "g.add_edge(2,7)\n",
    "g.add_edge(10,0)\n",
    "\n",
    "draw.graphlearn_draw(g, vertex_label='id')\n",
    "\n",
    "\n",
    "feas.rooted_problem_cycle(g,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print g.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stru,stri='(.((...))...)', 'aFaaaaaaaaaaa'\n",
    "\n",
    "\n",
    "\n",
    "def pairs(s):\n",
    "    \"give me a bond dict\"\n",
    "    unpaired=[]\n",
    "    pairs={}\n",
    "    for i,c in enumerate(s):\n",
    "        if c=='(':\n",
    "            unpaired.append(i)\n",
    "        if c==')':\n",
    "            partner=unpaired.pop()\n",
    "            pairs[i]=partner\n",
    "            pairs[partner]=i\n",
    "    return pairs\n",
    "\n",
    "\n",
    "\n",
    "def fix_structure( stru,stri ):\n",
    "    '''\n",
    "    the problem is to check every (( and )) . \n",
    "    if the bonding partners are not next to each other we know that we need to act.\n",
    "    '''\n",
    "    p=pairs(stru)\n",
    "    lastchar=\".\"\n",
    "    problems=[]\n",
    "    for i,c in enumerate(stru):\n",
    "        # checking for )) and ((\n",
    "        if c==lastchar and c!='.':\n",
    "            if abs(p[i]-p[i-1])!=1: #the partners are not next to each other\n",
    "                problems.append(i)\n",
    "        # )( provlem\n",
    "        elif c=='(':\n",
    "            if lastchar==')':\n",
    "                problems.append(i)          \n",
    "        lastchar=c\n",
    "            \n",
    "    problems.sort(reverse=True)\n",
    "    for i in problems:\n",
    "        stru=stru[:i]+'.'+stru[i:]\n",
    "        stri=stri[:i]+'F'+stri[i:]\n",
    "\n",
    "    return stru,stri\n",
    "    \n",
    "\n",
    "    \n",
    "fix_structure(stru,stri)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=[[4,5],[3,4]]\n",
    "l.sort()\n",
    "l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlearn.abstract_graphs.RnaWrap as RW\n",
    "from eden.converter.fasta import fasta_to_sequence   \n",
    "seq = [ b for (a,b) in fasta_to_sequence(\"RF00005.fa\") ] \n",
    "        \n",
    "folder=RW.NearestNeighborFolding(seq,4)\n",
    "\n",
    "folder.fold(\"GGGGCCUUAGCUCAGCUGGGAGAGCGCCUGCUUUGCACGCAGGAGGUCAGCGGUUCGAUGGCGCUAGGCUCCA\")\n",
    "a,b=folder.call_folder()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "textwrap.wrap(\"asdasdasdasdasdasd\", width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s=\"asdasdasdasd\"\n",
    "s.get(z,123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z=[1,2,3]\n",
    "z.reverse()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lol():\n",
    "    print \"a\"\n",
    "    return False\n",
    "\n",
    "if True or lol():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "import eden.modifier.rna.lib_forgi as lib_forgi\n",
    "\n",
    "\n",
    "\n",
    "def make_abstract_graph(forgi):\n",
    "    g=forgi_to_graph(forgi)\n",
    "    connect_multiloop(g)\n",
    "    return g\n",
    "\n",
    "\n",
    "def forgi_to_graph(forgi, ignore_inserts=True):\n",
    "    def make_node_set(numbers):\n",
    "        '''\n",
    "        forgi gives me stuff like define STEM START,END,START,END .. we take indices and output a list\n",
    "        '''\n",
    "        numbers=map(int,numbers)\n",
    "        ans=set()\n",
    "        while len(numbers)>1:\n",
    "            a,b = numbers[:2]\n",
    "            numbers=numbers[2:]\n",
    "            for n in range(a-1,b): ans.add(n) # should be range a,b+1 but the biologists are weired\n",
    "        return ans\n",
    "\n",
    "\n",
    "    def get_pairs(things):\n",
    "        '''\n",
    "        '''\n",
    "        current=[]\n",
    "        for thing in things:\n",
    "            if thing[0]=='m':\n",
    "                current.append(thing)\n",
    "            if len(current)==2:\n",
    "                yield current\n",
    "                current = []\n",
    "\n",
    "\n",
    "    g=nx.Graph()\n",
    "    fni={} # forgi name to networkx node id\n",
    "\n",
    "    for l in forgi.split('\\n')[:-1]:\n",
    "        line= l.split()\n",
    "        #only look at interesting lines\n",
    "        if line[0] not in ['define','connect']:\n",
    "            continue\n",
    "\n",
    "        # parse stuff like: define s0 1 7 65 71\n",
    "        if line[0]=='define':\n",
    "\n",
    "            # get necessary attributes for a node\n",
    "            label=line[1][0]\n",
    "            id=line[1]\n",
    "            myset=make_node_set(line[2:])\n",
    "            node_id=len(g)\n",
    "\n",
    "            # build a node and remember its id\n",
    "            g.add_node(node_id)\n",
    "            fni[id]=node_id\n",
    "            g.node[node_id].update( {'label':label, 'contracted':myset}  )\n",
    "\n",
    "        # parse stuff like this: connect s3 h2 m1 m3\n",
    "        if line[0]=='connect':\n",
    "            # get nx name of the first element.\n",
    "            hero= fni[ line[1] ]\n",
    "            # connect that hero to the following elements\n",
    "            for fn in line[2:]:\n",
    "                g.add_edge(hero, fni[fn])\n",
    "\n",
    "            # remember what pairs multiloop pieces we are part of\n",
    "            # i assume that if a stack is part of 2 multiloops they appear in order ..\n",
    "            # this assumption may be wrong so be careful\n",
    "            g.node[fni[line[1]]]['multipairs']=[]\n",
    "            for a,b in get_pairs(line[2:]):\n",
    "                g.node[fni[line[1]]]['multipairs'].append( (fni[a],fni[b]) )\n",
    "    if ignore_inserts:\n",
    "        # repair inserts by mergind adjacent stacks\n",
    "        mergelist=[]\n",
    "        for n,d in g.nodes(data=True):\n",
    "            if d['label']==\"i\":\n",
    "                neighs=g.neighbors(n)\n",
    "                mergelist.append((neighs[0],(n,neighs[1])))\n",
    "                \n",
    "        # merged is keeping track of already merged nodes.\n",
    "        # so we always know where to look for :) \n",
    "        merged={}\n",
    "        for s1,mergers in mergelist:\n",
    "            while s1 not in g.nodes():\n",
    "                s1=merged[s1]\n",
    "            for merger in mergers:\n",
    "                while merger not in g.nodes():\n",
    "                    merger=merged[merger]\n",
    "                merge(g,s1,merger)\n",
    "                merged[merger]=s1\n",
    "    return g\n",
    "\n",
    "def merge(graph, node, node2):\n",
    "    '''\n",
    "    merge node2 into the node.\n",
    "    input nodes are strings,\n",
    "    node is the king\n",
    "    '''\n",
    "    for n in graph.neighbors(node2):\n",
    "        graph.add_edge(node, n)\n",
    "    graph.node[node]['contracted'].update(graph.node[node2]['contracted'])\n",
    "    graph.remove_node(node2)\n",
    "\n",
    "\n",
    "def connect_multiloop(g):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    merge_dict={}\n",
    "    for node,d in g.nodes(data=True):\n",
    "        if d['label'] == 's':\n",
    "            for a,b in g.node[node]['multipairs']:\n",
    "                # finding real names... this works by walking up the\n",
    "                #ladder merge history until the root is found :)\n",
    "                while a not in g:\n",
    "                    a=merge_dict[a]\n",
    "                while b not in g:\n",
    "                    b=merge_dict[b]\n",
    "                if a==b:\n",
    "                    continue\n",
    "                merge_dict[b]=a\n",
    "                merge(g,a,b)\n",
    "\n",
    "s=\"((((((.(((((.((.......)).))))).............((((((...)))))).(((((.......))))).)))))).\"\n",
    "bg = lib_forgi.BulgeGraph()\n",
    "bg.from_dotbracket(s, None)\n",
    "forgi = bg.to_bg_string()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transform( original_graph):\n",
    "        \"\"\"Return a graph where the edges of the original_graph are converted to nodes.\"\"\"\n",
    "\n",
    "        # if operating on graphs that have already been subject to the\n",
    "        # edge_to_vertex transformation, then do not repeat the transformation but\n",
    "        # simply return the graph\n",
    "        if 'expanded' in original_graph.graph:\n",
    "            return original_graph\n",
    "        else:\n",
    "            graph = nx.Graph()\n",
    "            graph.graph['expanded'] = True\n",
    "            # build a graph that has as vertices the original vertex set\n",
    "            for n, d in original_graph.nodes_iter(data=True):\n",
    "                d['node'] = True\n",
    "                graph.add_node(n, d)\n",
    "            # and in addition a vertex for each edge\n",
    "            new_node_id = max(original_graph.nodes()) + 1\n",
    "            for u, v, d in original_graph.edges_iter(data=True):\n",
    "                d['edge'] = True\n",
    "                \n",
    "                graph.add_node(new_node_id, d)\n",
    "                print u,v,new_node_id\n",
    "                # and the corresponding edges\n",
    "                graph.add_edge(new_node_id, u, label=None)\n",
    "                graph.add_edge(new_node_id, v, label=None)\n",
    "                \n",
    "                new_node_id += 1\n",
    "            return graph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g=forgi_to_graph(forgi)\n",
    "draw.graphlearn(g,contract=False,secondary_vertex_label='id')\n",
    "\n",
    "if 2 in g[2]:\n",
    "    g.remove_edge(2,2)\n",
    "g = transform(g)\n",
    "draw.graphlearn(g,contract=False,secondary_vertex_label='id',size=20)\n",
    "#self._abstract_graph = forgi.edge_parent_finder(g, self._base_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rfam_uri(family_id):\n",
    "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "print rfam_uri(\"RF00162\")\n",
    "print rfam_uri(\"RF01725\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "x=range(14)\n",
    "yr=range(14)\n",
    "yc=range(14)\n",
    "bars = pylab.bar(x, yr, color='#88aa33', align='center')\n",
    "line = pylab.plot(x, yc, 'bo-')\n",
    "#pylab.legend((bars[0], line), ('', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "k=d.keys()\n",
    "k.sort()\n",
    "x=k\n",
    "\n",
    "def calc(text):\n",
    "    good=[]\n",
    "    bad=[]\n",
    "    var=[]\n",
    "    for line in text.splitlines():\n",
    "        \n",
    "        if len(line)>3:\n",
    "            n=line.split()\n",
    "            if line[0]=='b':\n",
    "                bad.append(float(n[1]))\n",
    "            elif line[0]=='c':\n",
    "                good.append(float(n[1]))\n",
    "            elif line[0]=='d':\n",
    "                var.append(float(n[2]))\n",
    "    return numpy.mean(good)/numpy.mean(bad),numpy.mean(var)\n",
    "\n",
    "difz=[]\n",
    "varz=[]\n",
    "for num in x:\n",
    "    dif,var= calc(d[k[0]])\n",
    "    difz.append(dif)\n",
    "    varz.append(var)\n",
    "\n",
    "bars = pylab.bar(x, difz, color='#88aa33', align='center')\n",
    "line = pylab.plot(x, varz, 'bo-')\n",
    "print difz\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={}\n",
    "d[92]='''afraction=0.100000 , instances=92.300000, good=58 , bad=34\n",
    "bad:mean/std  0.542810714801   0.349661607419\n",
    "cgood:mean/std  0.790736038444   0.231225302123\n",
    "dbad+good:mean/std  0.699111462315   0.305305608576\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=64 , bad=28\n",
    "bad:mean/std  0.688494507938   0.352989427074\n",
    "cgood:mean/std  0.734133463678   0.320827398543\n",
    "dbad+good:mean/std  0.720243346714   0.331612473595\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=55 , bad=37\n",
    "bad:mean/std  0.546389154014   0.332194421667\n",
    "cgood:mean/std  0.835143474818   0.217328597718\n",
    "dbad+good:mean/std  0.719014019712   0.304408175323\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=67 , bad=25\n",
    "bad:mean/std  0.402207206204   0.273834974364\n",
    "cgood:mean/std  0.807374637286   0.184093133028\n",
    "dbad+good:mean/std  0.697274791883   0.27846791812\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=55 , bad=37\n",
    "bad:mean/std  0.572282272933   0.350851114201\n",
    "cgood:mean/std  0.829698090215   0.255046790544\n",
    "dbad+good:mean/std  0.726172163699   0.322994899336'''\n",
    "\n",
    "\n",
    "d[230]='''afraction=0.250000 , instances=230.750000, good=155 , bad=75\n",
    "bad:mean/std  0.640075595111   0.283305514037\n",
    "cgood:mean/std  0.737494110715   0.238419717907\n",
    "dbad+good:mean/std  0.705727203453   0.25800355012\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=137 , bad=93\n",
    "bad:mean/std  0.594862186032   0.343494726677\n",
    "cgood:mean/std  0.805313798506   0.224577002806\n",
    "dbad+good:mean/std  0.720218146505   0.297350480688\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=157 , bad=73\n",
    "bad:mean/std  0.639771485915   0.274518125113\n",
    "cgood:mean/std  0.769124823968   0.207595367144\n",
    "dbad+good:mean/std  0.728069199281   0.238665839597\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=150 , bad=80\n",
    "bad:mean/std  0.530699501172   0.390007230272\n",
    "cgood:mean/std  0.809755617956   0.301870278807\n",
    "dbad+good:mean/std  0.712692620814   0.360556360047\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=143 , bad=87\n",
    "bad:mean/std  0.590356592949   0.286091113985\n",
    "cgood:mean/std  0.777214165137   0.217968641828\n",
    "dbad+good:mean/std  0.706533257396   0.262126774201'''\n",
    "\n",
    "d[461]='''afraction=0.500000 , instances=461.500000, good=291 , bad=170\n",
    "bad:mean/std  0.622543365822   0.235976515464\n",
    "cgood:mean/std  0.766928992566   0.230385106261\n",
    "dbad+good:mean/std  0.713684835198   0.24267600347\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=272 , bad=189\n",
    "bad:mean/std  0.672158372849   0.302155433385\n",
    "cgood:mean/std  0.721554421998   0.318655618573\n",
    "dbad+good:mean/std  0.701303113345   0.312940906054\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=293 , bad=168\n",
    "bad:mean/std  0.566424613889   0.381794234997\n",
    "cgood:mean/std  0.778188814386   0.287494252347\n",
    "dbad+good:mean/std  0.701016611168   0.340646439478\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=286 , bad=175\n",
    "bad:mean/std  0.629601316706   0.321176518219\n",
    "cgood:mean/std  0.775593653265   0.255392461042\n",
    "dbad+good:mean/std  0.720173568888   0.29093480224\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=275 , bad=186\n",
    "bad:mean/std  0.594475443226   0.33710950575\n",
    "cgood:mean/std  0.780450672165   0.289364719126\n",
    "dbad+good:mean/std  0.705415113417   0.322683318829'''\n",
    "\n",
    "d[692]='''afraction=0.750000 , instances=692.250000, good=408 , bad=284\n",
    "bad:mean/std  0.635792316651   0.274649232163\n",
    "cgood:mean/std  0.778003481934   0.251340666137\n",
    "dbad+good:mean/std  0.719639362078   0.270365269585\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=410 , bad=282\n",
    "bad:mean/std  0.571209986585   0.386982171446\n",
    "cgood:mean/std  0.800889289117   0.294441903269\n",
    "dbad+good:mean/std  0.70729165427   0.353737866644\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=400 , bad=292\n",
    "bad:mean/std  0.634680386953   0.348509854566\n",
    "cgood:mean/std  0.747700988141   0.311335620803\n",
    "dbad+good:mean/std  0.700010214229   0.332258922463\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=418 , bad=274\n",
    "bad:mean/std  0.663718539519   0.286590234979\n",
    "cgood:mean/std  0.760241847752   0.266779386761\n",
    "dbad+good:mean/std  0.722023081198   0.278819475054\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=400 , bad=292\n",
    "bad:mean/std  0.642283909387   0.344101370928\n",
    "cgood:mean/std  0.756517414073   0.304975567452\n",
    "dbad+good:mean/std  0.708314836951   0.326969484795'''\n",
    "\n",
    "d[923]='''afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.658508602551   0.276195694166\n",
    "cgood:mean/std  0.771326113551   0.243804950417\n",
    "dbad+good:mean/std  0.72170107621   0.264547924335\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.643009372391   0.295332211788\n",
    "cgood:mean/std  0.768262566357   0.264059224087\n",
    "dbad+good:mean/std  0.713167445285   0.285109903747\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.653162688584   0.335352182962\n",
    "cgood:mean/std  0.76655186239   0.297097974329\n",
    "dbad+good:mean/std  0.716675367737   0.319495161158\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.651569439642   0.331891581894\n",
    "cgood:mean/std  0.752260237527   0.307620926593\n",
    "dbad+good:mean/std  0.707969377352   0.322422128354\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.6538610847   0.345500044461\n",
    "cgood:mean/std  0.743075692029   0.310176036932\n",
    "dbad+good:mean/std  0.70383286367   0.329177890577'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2={}\n",
    "d2[92]='''afraction=0.100000 , instances=92.300000, good=58 , bad=34\n",
    "bad:mean/std  0.562640353661   0.235685663594\n",
    "cgood:mean/std  0.785123989938   0.16584208864\n",
    "dbad+good:mean/std  0.702901776531   0.222261871136\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=64 , bad=28\n",
    "bad:mean/std  0.338659812503   0.346338851321\n",
    "cgood:mean/std  0.88728511472   0.159039879238\n",
    "dbad+good:mean/std  0.720312196654   0.343260720579\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=55 , bad=37\n",
    "bad:mean/std  0.404849590464   0.365395032395\n",
    "cgood:mean/std  0.941587012007   0.0962036949533\n",
    "dbad+good:mean/std  0.725725222908   0.358459784971\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=67 , bad=25\n",
    "bad:mean/std  0.15023769209   0.230001571562\n",
    "cgood:mean/std  0.946015739189   0.0504978175025\n",
    "dbad+good:mean/std  0.729771704651   0.376235373441\n",
    "\n",
    "afraction=0.100000 , instances=92.300000, good=55 , bad=37\n",
    "bad:mean/std  0.397720210905   0.335216976296\n",
    "cgood:mean/std  0.948443874284   0.0269816355303\n",
    "dbad+good:mean/std  0.726957183577   0.344309863502'''\n",
    "\n",
    "d2[230]='''afraction=0.250000 , instances=230.750000, good=155 , bad=75\n",
    "bad:mean/std  0.339920565217   0.429762029243\n",
    "cgood:mean/std  0.911686818139   0.116093601057\n",
    "dbad+good:mean/std  0.725241300882   0.375700544929\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=137 , bad=93\n",
    "bad:mean/std  0.396143440364   0.372563754593\n",
    "cgood:mean/std  0.935973217454   0.10335714879\n",
    "dbad+good:mean/std  0.717694220631   0.364247100758\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=157 , bad=73\n",
    "bad:mean/std  0.268728433828   0.401798311392\n",
    "cgood:mean/std  0.93346904819   0.117359397723\n",
    "dbad+good:mean/std  0.722486157545   0.395445434157\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=150 , bad=80\n",
    "bad:mean/std  0.339144852202   0.346445794566\n",
    "cgood:mean/std  0.918346633244   0.142644738127\n",
    "dbad+good:mean/std  0.716885144186   0.362102143133\n",
    "\n",
    "afraction=0.250000 , instances=230.750000, good=143 , bad=87\n",
    "bad:mean/std  0.352561633096   0.382065168077\n",
    "cgood:mean/std  0.945525168377   0.137159677799\n",
    "dbad+good:mean/std  0.721230265901   0.386785869095'''\n",
    "\n",
    "d2[461]='''afraction=0.500000 , instances=461.500000, good=291 , bad=170\n",
    "bad:mean/std  0.379505459118   0.459455373226\n",
    "cgood:mean/std  0.927778413289   0.16583855546\n",
    "dbad+good:mean/std  0.725595328237   0.406423126819\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=272 , bad=189\n",
    "bad:mean/std  0.396325857612   0.37929866902\n",
    "cgood:mean/std  0.941420875285   0.106833385017\n",
    "dbad+good:mean/std  0.717943742226   0.370932508828\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=293 , bad=168\n",
    "bad:mean/std  0.333768529204   0.440671183226\n",
    "cgood:mean/std  0.948929775974   0.13941262968\n",
    "dbad+good:mean/std  0.724749538539   0.413244833972\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=286 , bad=175\n",
    "bad:mean/std  0.358126766908   0.379732510884\n",
    "cgood:mean/std  0.942972327989   0.117402427308\n",
    "dbad+good:mean/std  0.720959370963   0.379266475678\n",
    "\n",
    "afraction=0.500000 , instances=461.500000, good=275 , bad=186\n",
    "bad:mean/std  0.412713491754   0.422883653728\n",
    "cgood:mean/std  0.927391603915   0.134935559383\n",
    "dbad+good:mean/std  0.719734057577   0.383104960866'''\n",
    "\n",
    "d2[692]='''afraction=0.750000 , instances=692.250000, good=408 , bad=284\n",
    "bad:mean/std  0.371963806388   0.398061119404\n",
    "cgood:mean/std  0.922353449792   0.128123926446\n",
    "dbad+good:mean/std  0.696470994984   0.384719153823\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=410 , bad=282\n",
    "bad:mean/std  0.416536710607   0.377957385011\n",
    "cgood:mean/std  0.929570055521   0.153515052258\n",
    "dbad+good:mean/std  0.720501553692   0.368411009188\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=400 , bad=292\n",
    "bad:mean/std  0.441178062347   0.417406626024\n",
    "cgood:mean/std  0.919603237706   0.162193575642\n",
    "dbad+good:mean/std  0.717724406485   0.380201744412\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=418 , bad=274\n",
    "bad:mean/std  0.542234001566   0.328979723695\n",
    "cgood:mean/std  0.80748489789   0.237997671718\n",
    "dbad+good:mean/std  0.702457808883   0.306424401882\n",
    "\n",
    "afraction=0.750000 , instances=692.250000, good=400 , bad=292\n",
    "bad:mean/std  0.44163920813   0.454626882481\n",
    "cgood:mean/std  0.924610067045   0.165694104189\n",
    "dbad+good:mean/std  0.720813115017   0.399973275688'''\n",
    "\n",
    "d2[923]='''afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.469109343043   0.415605791911\n",
    "cgood:mean/std  0.933671263935   0.133254522612\n",
    "dbad+good:mean/std  0.729324416825   0.37295866873\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.43044946941   0.437342578913\n",
    "cgood:mean/std  0.945117651785   0.119158428913\n",
    "dbad+good:mean/std  0.71873056398   0.396673089235\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.42871096708   0.435697421371\n",
    "cgood:mean/std  0.939334334925   0.124988974242\n",
    "dbad+good:mean/std  0.714726439643   0.395592375432\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.469885462733   0.407889201948\n",
    "cgood:mean/std  0.915432063546   0.187010222823\n",
    "dbad+good:mean/std  0.719449485074   0.376407070421\n",
    "\n",
    "afraction=1.000000 , instances=923.000000, good=517 , bad=406\n",
    "bad:mean/std  0.491963604317   0.404352701889\n",
    "cgood:mean/std  0.909400489088   0.201032775385\n",
    "dbad+good:mean/std  0.725782531107   0.370796140146'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=0\n",
    "eval(\"a=[1,2]\",a)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

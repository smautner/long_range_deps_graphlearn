{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import eden\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import Sampler as GraphLearnSampler\n",
    "from eden.util import fit,estimate\n",
    "from eden.path import Vectorizer\n",
    "import random\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "import random\n",
    "'''\n",
    "GET RNA DATA\n",
    "'''\n",
    "\n",
    "logger = logging.getLogger()\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import itertools\n",
    "\n",
    "def rfam_uri(family_id):\n",
    "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "def rfam_uri(family_id):\n",
    "    return '%s.fa'%(family_id)\n",
    " \n",
    "\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "def get_sequences_with_names(filename='RF00005.fa'):\n",
    "    sequences = fasta_to_sequence(\"../toolsdata/\"+filename)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_graphs(fname,size):\n",
    "    graphs=[g for g in get_sequences_with_names(fname)]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size]\n",
    "\n",
    "\n",
    "# permuted get_graphs\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import random \n",
    "def permute_sequence(st):\n",
    "    st=list(st)    \n",
    "    random.shuffle(st)\n",
    "    return ''.join(st)\n",
    "def read_and_permute(samples='RF00005.fa'):\n",
    "    for name,seq in fasta_to_sequence(samples):\n",
    "        seq=permute_sequence(seq)\n",
    "        yield (name,seq)\n",
    "\n",
    "def get_graphs_permuted(fname='RF00005.fa',size=99999):\n",
    "    graphs=[g for g in read_and_permute(\"../toolsdata/\"+fname)]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size]\n",
    "\n",
    "\n",
    "\n",
    "# formerly:\n",
    "#get_graphs(dataset_fname, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "from graphlearn.estimator import Wrapper as estimatorwrapper\n",
    "import graphlearn.utils.draw as draw\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def fit_sample(graphs, random_state=random.random()):\n",
    "    '''\n",
    "    graphs -> more graphs\n",
    "    '''\n",
    "    graphs = list(graphs)\n",
    "    estimator=estimatorwrapper( nu=.5, cv=2, n_jobs=-1)\n",
    "    sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                                thickness_list=[2], \n",
    "                                min_cip_count=1, \n",
    "                                min_interface_count=2, \n",
    "                                preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                                postprocessor=rna.PostProcessor(),\n",
    "                                estimator=estimator\n",
    "                                #feasibility_checker=feasibility\n",
    "                               )\n",
    "    sampler.fit(graphs,grammar_n_jobs=4,grammar_batch_size=1)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    logger.info('graph grammar stats:')\n",
    "    dataset_size, interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#instances:%d   #interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (dataset_size, interface_counts, core_counts, cip_counts))\n",
    "    \n",
    "    \n",
    "    graphs = [ b for a ,b in graphs  ]\n",
    "    \n",
    "    graphs = sampler.sample(graphs,\n",
    "                            n_samples=3,\n",
    "                            batch_size=1,\n",
    "                            n_steps=50,\n",
    "                            n_jobs=4,\n",
    "                            quick_skip_orig_cip=True,\n",
    "                            probabilistic_core_choice=True,\n",
    "                            burnin=10,\n",
    "                            improving_threshold=0.9,\n",
    "                            improving_linear_start=0.3,\n",
    "                            max_size_diff=20,\n",
    "                            accept_min_similarity=0.65,\n",
    "                            select_cip_max_tries=30,\n",
    "                            keep_duplicates=False,\n",
    "                            include_seed=False,\n",
    "                            backtrack=10,\n",
    "                            monitor=False)\n",
    "    result=[]\n",
    "    for graphlist in graphs:\n",
    "        result+=graphlist\n",
    "    # note that this is a list [('',sequ),..]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(pos_original, neg_original,\n",
    "                     pos_sampled, neg_sampled,\n",
    "                     pos_test, neg_test,\n",
    "                     random_state=42):\n",
    "    '''\n",
    "    pos + neg orig+sampled testsets -> orig_roc , sampled_roc, augmented_roc\n",
    "    '''\n",
    "    \n",
    "    # create graph sets...orig augmented and sampled\n",
    "    pos_orig,pos_orig_ = tee(pos_original)\n",
    "    neg_orig,neg_orig_ = tee(neg_original)\n",
    "    \n",
    "    pos_sampled, pos_sampled_ = tee(pos_sampled)\n",
    "    neg_sampled, neg_sampled_ = tee(neg_sampled)\n",
    "    \n",
    "    pos_augmented = chain(pos_orig_,pos_sampled_)\n",
    "    neg_augmented = chain(neg_orig_,neg_sampled_)\n",
    "\n",
    "    predictive_performances = []\n",
    "    for desc,pos_train,neg_train in [('original',pos_orig, neg_orig),\n",
    "                                     ('sample',pos_sampled,neg_sampled),\n",
    "                                     ('original+sample',pos_augmented, neg_augmented)]:\n",
    "        pos_train,pos_train_ = tee(pos_train)\n",
    "        neg_train,neg_train_ = tee(neg_train)\n",
    "        pos_size=sum(1 for x in pos_train_)\n",
    "        neg_size=sum(1 for x in neg_train_)\n",
    "\n",
    "        logger.info( \"-\"*80)\n",
    "        logger.info('working on %s'%(desc))\n",
    "        logger.info('training set sizes: #pos: %d #neg: %d'%(pos_size, neg_size))\n",
    "\n",
    "        if pos_size == 0 or neg_size == 0:\n",
    "            logger.info('WARNING: empty dataset')\n",
    "            predictive_performances.append(0)            \n",
    "        else:\n",
    "            start=time()\n",
    "            pos_test,pos_test_ = tee(pos_test)\n",
    "            neg_test,neg_test_ = tee(neg_test)\n",
    "            \n",
    "            local_estimator = fit(pos_train, neg_train, Vectorizer(4), n_jobs=-1, n_iter_search=1)\n",
    "            apr, roc = estimate(pos_test_, neg_test_, local_estimator, Vectorizer(4))\n",
    "            predictive_performances.append(roc)\n",
    "            logger.info( 'elapsed: %.1f sec'%(time()-start))\n",
    "    return predictive_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pos_fname, neg_fname=None, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs_pos = get_graphs(pos_fname, size=size)\n",
    "    \n",
    "    if neg_fname==None:\n",
    "        graphs_neg = get_graphs_permuted(pos_fname, size=size)\n",
    "    else:    \n",
    "        graphs_neg = get_graphs(neg_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    pos_train_global,pos_test_global = random_bipartition_iter(graphs_pos,train_test_split,random_state=random.random()*1000)\n",
    "    neg_train_global,neg_test_global = random_bipartition_iter(graphs_neg,train_test_split,random_state=random.random()*1000)\n",
    "\n",
    "\n",
    "    original_repetitions = []\n",
    "    original_sample_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random_state = int(313379*percentage+repetition) \n",
    "            random.seed(random_state)\n",
    "            pos_train_global,pos_train_global_ = tee(pos_train_global)\n",
    "            neg_train_global,neg_train_global_ = tee(neg_train_global)\n",
    "            pos_test_global,pos_test_global_ = tee(pos_test_global)\n",
    "            neg_test_global,neg_test_global_ = tee(neg_test_global)\n",
    "\n",
    "            # use shuffled list to create test and sample set\n",
    "            pos,pos_reminder = random_bipartition_iter(pos_train_global_,percentage)\n",
    "            pos,pos_ = tee(pos)\n",
    "            neg,neg_reminder = random_bipartition_iter(neg_train_global_,percentage)\n",
    "            neg,neg_ = tee(neg)\n",
    "\n",
    "            #sample independently from the 2 classes\n",
    "            logger.info('Positive')\n",
    "            sampled_pos = fit_sample(pos_, random_state=random_state)\n",
    "            logger.info('Negative')\n",
    "            sampled_neg = fit_sample(neg_, random_state=random_state)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            logger.info( \"=\"*80)\n",
    "            logger.info( 'repetition: %d/%d'%(repetition+1, n_repetitions))\n",
    "            logger.info( \"training percentage:\"+str(percentage))\n",
    "            perf_orig,\\\n",
    "            perf_samp,\\\n",
    "            perf_orig_samp = fit_and_evaluate(pos,neg,\n",
    "                                              sampled_pos,sampled_neg,\n",
    "                                              pos_test_global_,neg_test_global_)\n",
    "            logger.info( 'Time elapsed for full repetition: %.1f sec'%((time()-start)))\n",
    "            originals.append(perf_orig)\n",
    "            originals_samples.append(perf_orig_samp)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        original_sample_repetitions.append(originals_samples)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, original_sample_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    ws = 0.02\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original+sample')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.title(dataset+'\\n',fontsize=17)\n",
    "    plt.legend(loc='lower right',fontsize=16)\n",
    "    plt.ylabel('ROC AUC',fontsize=16)\n",
    "    plt.xlabel('Dataset size (fraction)',fontsize=16)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions):\n",
    "    with open(result_fname,'w') as f:\n",
    "        f.write('dataset sizes list:\\n')\n",
    "        for perc in percentages:\n",
    "            f.write('%s '% perc)\n",
    "        f.write('\\n')\n",
    "        f.write('AUC scores:\\n')\n",
    "        for repetitions in original_repetitions,original_sample_repetitions,sample_repetitions:\n",
    "            f.write('%s\\n' % len(repetitions))\n",
    "            for repetition in repetitions:\n",
    "                for auc in repetition:\n",
    "                    f.write('%s ' % auc)\n",
    "                f.write('\\n')\n",
    "    \n",
    "def load_results(result_fname):\n",
    "    with open(result_fname) as f:\n",
    "        comment = next(f)\n",
    "        line = next(f)\n",
    "        percentages = [float(x) for x in line.split()]\n",
    "        comment = next(f)\n",
    "\n",
    "        original_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_repetitions.append(repetition)\n",
    "\n",
    "        original_sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_sample_repetitions.append(repetition)\n",
    "\n",
    "\n",
    "        sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            sample_repetitions.append(repetition)\n",
    "            \n",
    "    return percentages, original_repetitions,original_sample_repetitions,sample_repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experimental pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot(\"RF00162 vs RF01725\", percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with dataset: RF00005.fa_vs_None\n",
      "Working with dataset: RF00005.fa_vs_None\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:5   #interfaces: 16   #cores: 45   #core-interface-pairs: 45\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:5   #interfaces: 9   #cores: 20   #core-interface-pairs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1/martners/.local/miniconda2/lib/python2.7/site-packages/sklearn/calibration.py:489: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(self.a_ * T + self.b_))\n",
      "/scratch/1/martners/.local/miniconda2/lib/python2.7/site-packages/sklearn/calibration.py:489: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(self.a_ * T + self.b_))\n",
      "/scratch/1/martners/.local/miniconda2/lib/python2.7/site-packages/sklearn/calibration.py:489: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(self.a_ * T + self.b_))\n",
      "/scratch/1/martners/.local/miniconda2/lib/python2.7/site-packages/sklearn/calibration.py:489: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(self.a_ * T + self.b_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "repetition: 1/5\n",
      "training percentage:0.08\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 5 #neg: 5\n",
      "Test set\n",
      "Instances: 60 ; Features: 1048577 with an avg of 1556 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.97      0.75        30\n",
      "          1       0.92      0.40      0.56        30\n",
      "\n",
      "avg / total       0.77      0.68      0.66        60\n",
      "\n",
      "APR: 0.860\n",
      "ROC: 0.830\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.767 +- 0.097\n",
      "           precision: 0.768 +- 0.131\n",
      "              recall: 0.800 +- 0.125\n",
      "                  f1: 0.775 +- 0.092\n",
      "   average_precision: 0.913 +- 0.041\n",
      "             roc_auc: 0.894 +- 0.064\n",
      "elapsed: 3.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 10 #neg: 8\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-582064910088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-582064910088>\u001b[0m in \u001b[0;36mdo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                                       \u001b[0mpercentages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpercentages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                       \u001b[0mn_repetitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                                       train_test_split=0.7)\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m#save and display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpercentages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_repetitions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginal_sample_repetitions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_repetitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d28d9501dffb>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(pos_fname, neg_fname, size, percentages, n_repetitions, train_test_split)\u001b[0m\n\u001b[1;32m     49\u001b[0m             perf_orig,            perf_samp,            perf_orig_samp = fit_and_evaluate(pos,neg,\n\u001b[1;32m     50\u001b[0m                                               \u001b[0msampled_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msampled_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                                               pos_test_global_,neg_test_global_)\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Time elapsed for full repetition: %.1f sec'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moriginals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e65bfe635d59>\u001b[0m in \u001b[0;36mfit_and_evaluate\u001b[0;34m(pos_original, neg_original, pos_sampled, neg_sampled, pos_test, neg_test, random_state)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mneg_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_test_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mlocal_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mapr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_test_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_test_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mpredictive_performances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/1/mautner/oldthings/EDeN/eden/util/__init__.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(iterable_pos, iterable_neg, vectorizer, estimator, fit_flag, n_jobs, cv, n_iter_search, random_state, n_blocks, block_size)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                      \u001b[0mn_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                                      \u001b[0mblock_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                                      n_jobs=n_jobs)\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Positive data: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_data_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miterable_neg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/1/mautner/oldthings/EDeN/eden/util/__init__.pyc\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(graphs, vectorizer, fit_flag, n_blocks, block_size, n_jobs)\u001b[0m\n\u001b[1;32m    220\u001b[0m                                       \u001b[0mn_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                                       \u001b[0mblock_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                                       n_jobs=n_jobs)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/1/mautner/oldthings/EDeN/eden/util/__init__.pyc\u001b[0m in \u001b[0;36mmultiprocess_vectorize\u001b[0;34m(graphs, vectorizer, fit_flag, n_blocks, block_size, n_jobs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     results = [apply_async(pool, serial_vectorize, args=(graphs[start:end], vectorizer, False))\n\u001b[1;32m    205\u001b[0m                for start, end in intervals]\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/1/martners/.local/miniconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type"
     ]
    }
   ],
   "source": [
    "def do():\n",
    "    #special case: bursi\n",
    "    pos_dataset_fname = 'RF00005.fa'\n",
    "    neg_dataset_fname = None # none will permute the first dataset\n",
    "    dataset='%s_vs_%s' % (pos_dataset_fname, neg_dataset_fname)\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    result_fname = 'asd.data'\n",
    "    if True:\n",
    "        #logging\n",
    "        \n",
    "        if True:\n",
    "            logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "        else:\n",
    "            logger_fname = None\n",
    "        configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "\n",
    "        #main \n",
    "        start=time()\n",
    "        print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "        logger.info( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "        percentages=[.08,.2,.4,.6,.8,.95]\n",
    "        #percentages=[.07,0.1,0.15,0.2]\n",
    "\n",
    "        # set size to 900 in production\n",
    "        original_repetitions,\\\n",
    "        original_sample_repetitions,\\\n",
    "        sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                                      neg_dataset_fname,\n",
    "                                      size=100,\n",
    "                                      percentages=percentages,\n",
    "                                      n_repetitions=5,\n",
    "                                      train_test_split=0.7)\n",
    "        #save and display results\n",
    "        save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions)    \n",
    "\n",
    "    \n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "\n",
    "    #print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "\n",
    "do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

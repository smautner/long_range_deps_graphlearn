{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikea/.local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/ikea/miniconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ikea/miniconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import eden\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import Sampler as GraphLearnSampler\n",
    "from eden.util import fit,estimate\n",
    "from eden.path import Vectorizer\n",
    "import random\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "import random\n",
    "'''\n",
    "GET RNA DATA\n",
    "'''\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import itertools\n",
    "\n",
    "def rfam_uri(family_id):\n",
    "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "def rfam_uri(family_id):\n",
    "    return '%s.fa'%(family_id)\n",
    " \n",
    "\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "def get_sequences_with_names(filename='RF00005.fa'):\n",
    "    sequences = fasta_to_sequence(\"../toolsdata/\"+filename)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_graphs(fname,size):\n",
    "    graphs=[g for g in get_sequences_with_names(fname)]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size]\n",
    "\n",
    "# formerly:\n",
    "#get_graphs(dataset_fname, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "from graphlearn.estimator import Wrapper as estimatorwrapper\n",
    "import graphlearn.utils.draw as draw\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def fit_sample(graphs, random_state=random.random()):\n",
    "    '''\n",
    "    graphs -> more graphs\n",
    "    '''\n",
    "    graphs = list(graphs)\n",
    "    estimator=estimatorwrapper( nu=.5, cv=2, n_jobs=-1)\n",
    "    sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                                thickness_list=[2], \n",
    "                                min_cip_count=1, \n",
    "                                min_interface_count=2, \n",
    "                                preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                                postprocessor=rna.PostProcessor(),\n",
    "                                estimator=estimator\n",
    "                                #feasibility_checker=feasibility\n",
    "                               )\n",
    "    sampler.fit(graphs,grammar_n_jobs=4,grammar_batch_size=1)\n",
    "    \n",
    "    \n",
    "    logger.info('graph grammar stats:')\n",
    "    dataset_size, interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#instances:%d   #interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (dataset_size, interface_counts, core_counts, cip_counts))\n",
    "    \n",
    "    \n",
    "    graphs = [ b for a ,b in graphs  ]\n",
    "    \n",
    "    graphs = sampler.sample(graphs,\n",
    "                            n_samples=3,\n",
    "                            batch_size=1,\n",
    "                            n_steps=50,\n",
    "                            n_jobs=4,\n",
    "                            quick_skip_orig_cip=True,\n",
    "                            probabilistic_core_choice=True,\n",
    "                            burnin=10,\n",
    "                            improving_threshold=0.9,\n",
    "                            improving_linear_start=0.3,\n",
    "                            max_size_diff=20,\n",
    "                            accept_min_similarity=0.65,\n",
    "                            select_cip_max_tries=30,\n",
    "                            keep_duplicates=False,\n",
    "                            include_seed=False,\n",
    "                            backtrack=10,\n",
    "                            monitor=False)\n",
    "    result=[]\n",
    "    for graphlist in graphs:\n",
    "        result+=graphlist\n",
    "    # note that this is a list [('',sequ),..]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(pos_original, neg_original,\n",
    "                     pos_sampled, neg_sampled,\n",
    "                     pos_test, neg_test,\n",
    "                     random_state=42):\n",
    "    '''\n",
    "    pos + neg orig+sampled testsets -> orig_roc , sampled_roc, augmented_roc\n",
    "    '''\n",
    "    \n",
    "    # create graph sets...orig augmented and sampled\n",
    "    pos_orig,pos_orig_ = tee(pos_original)\n",
    "    neg_orig,neg_orig_ = tee(neg_original)\n",
    "    \n",
    "    pos_sampled, pos_sampled_ = tee(pos_sampled)\n",
    "    neg_sampled, neg_sampled_ = tee(neg_sampled)\n",
    "    \n",
    "    pos_augmented = chain(pos_orig_,pos_sampled_)\n",
    "    neg_augmented = chain(neg_orig_,neg_sampled_)\n",
    "\n",
    "    predictive_performances = []\n",
    "    for desc,pos_train,neg_train in [('original',pos_orig, neg_orig),\n",
    "                                     ('sample',pos_sampled,neg_sampled),\n",
    "                                     ('original+sample',pos_augmented, neg_augmented)]:\n",
    "        pos_train,pos_train_ = tee(pos_train)\n",
    "        neg_train,neg_train_ = tee(neg_train)\n",
    "        pos_size=sum(1 for x in pos_train_)\n",
    "        neg_size=sum(1 for x in neg_train_)\n",
    "\n",
    "        logger.info( \"-\"*80)\n",
    "        logger.info('working on %s'%(desc))\n",
    "        logger.info('training set sizes: #pos: %d #neg: %d'%(pos_size, neg_size))\n",
    "\n",
    "        if pos_size == 0 or neg_size == 0:\n",
    "            logger.info('WARNING: empty dataset')\n",
    "            predictive_performances.append(0)            \n",
    "        else:\n",
    "            start=time()\n",
    "            pos_test,pos_test_ = tee(pos_test)\n",
    "            neg_test,neg_test_ = tee(neg_test)\n",
    "            \n",
    "            local_estimator = fit(pos_train, neg_train, Vectorizer(4), n_jobs=-1, n_iter_search=1)\n",
    "            apr, roc = estimate(pos_test_, neg_test_, local_estimator, Vectorizer(4))\n",
    "            predictive_performances.append(roc)\n",
    "            logger.info( 'elapsed: %.1f sec'%(time()-start))\n",
    "    return predictive_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pos_fname, neg_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs_pos = get_graphs(pos_fname, size=size)\n",
    "    graphs_neg = get_graphs(neg_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    pos_train_global,pos_test_global = random_bipartition_iter(graphs_pos,train_test_split,random_state=random.random()*1000)\n",
    "    neg_train_global,neg_test_global = random_bipartition_iter(graphs_neg,train_test_split,random_state=random.random()*1000)\n",
    "\n",
    "\n",
    "    original_repetitions = []\n",
    "    original_sample_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random_state = int(313379*percentage+repetition) \n",
    "            random.seed(random_state)\n",
    "            pos_train_global,pos_train_global_ = tee(pos_train_global)\n",
    "            neg_train_global,neg_train_global_ = tee(neg_train_global)\n",
    "            pos_test_global,pos_test_global_ = tee(pos_test_global)\n",
    "            neg_test_global,neg_test_global_ = tee(neg_test_global)\n",
    "\n",
    "            # use shuffled list to create test and sample set\n",
    "            pos,pos_reminder = random_bipartition_iter(pos_train_global_,percentage)\n",
    "            pos,pos_ = tee(pos)\n",
    "            neg,neg_reminder = random_bipartition_iter(neg_train_global_,percentage)\n",
    "            neg,neg_ = tee(neg)\n",
    "\n",
    "            #sample independently from the 2 classes\n",
    "            logger.info('Positive')\n",
    "            sampled_pos = fit_sample(pos_, random_state=random_state)\n",
    "            logger.info('Negative')\n",
    "            sampled_neg = fit_sample(neg_, random_state=random_state)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            logger.info( \"=\"*80)\n",
    "            logger.info( 'repetition: %d/%d'%(repetition+1, n_repetitions))\n",
    "            logger.info( \"training percentage:\"+str(percentage))\n",
    "            perf_orig,\\\n",
    "            perf_samp,\\\n",
    "            perf_orig_samp = fit_and_evaluate(pos,neg,\n",
    "                                              sampled_pos,sampled_neg,\n",
    "                                              pos_test_global_,neg_test_global_)\n",
    "            logger.info( 'Time elapsed for full repetition: %.1f sec'%((time()-start)))\n",
    "            originals.append(perf_orig)\n",
    "            originals_samples.append(perf_orig_samp)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        original_sample_repetitions.append(originals_samples)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, original_sample_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    FONTSIZE=20\n",
    "    ws = 1\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    ax = plt.subplot() \n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(20)\n",
    "    \n",
    "    \n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original+sample')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.xlim(2,15)\n",
    "    #plt.ylim(0.99,1.005)\n",
    "    plt.ylim(0.0,1.005)\n",
    "    plt.title(dataset+'\\n',fontsize=20)\n",
    "    plt.legend(loc='lower right',fontsize=18)\n",
    "    plt.ylabel('ROC AUC',fontsize=18)\n",
    "    plt.xlabel('Training set size per family',fontsize=18)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)\n",
    "\n",
    "#load(\"DATAS\")\n",
    "#plot(\"RF00162 vs RF00005 learning curve\", percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions):\n",
    "    with open(result_fname,'w') as f:\n",
    "        f.write('dataset sizes list:\\n')\n",
    "        for perc in percentages:\n",
    "            f.write('%s '% perc)\n",
    "        f.write('\\n')\n",
    "        f.write('AUC scores:\\n')\n",
    "        for repetitions in original_repetitions,original_sample_repetitions,sample_repetitions:\n",
    "            f.write('%s\\n' % len(repetitions))\n",
    "            for repetition in repetitions:\n",
    "                for auc in repetition:\n",
    "                    f.write('%s ' % auc)\n",
    "                f.write('\\n')\n",
    "    \n",
    "def load_results(result_fname):\n",
    "    with open(result_fname) as f:\n",
    "        comment = next(f)\n",
    "        line = next(f)\n",
    "        percentages = [float(x) for x in line.split()]\n",
    "        comment = next(f)\n",
    "\n",
    "        original_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_repetitions.append(repetition)\n",
    "\n",
    "        original_sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_sample_repetitions.append(repetition)\n",
    "\n",
    "\n",
    "        sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            sample_repetitions.append(repetition)\n",
    "            \n",
    "    return percentages, original_repetitions,original_sample_repetitions,sample_repetitions\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experimental pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot(\"RF00162 vs RF01725\", percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "\n",
    "#print '%s_predictive_performance_of_samples.data'%dataset\n",
    "#!cat \"RF00162 vs RF00005 training curve_predictive_performance_of_samples.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\n",
    "#plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%%time\n",
    "#special case: bursi\n",
    "\n",
    "dataset='RF00162 vs RF00005 training curve'\n",
    "#logging\n",
    "logger = logging.getLogger()\n",
    "if True:\n",
    "    logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "else:\n",
    "    logger_fname = None\n",
    "configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "\n",
    "#main \n",
    "start=time()\n",
    "print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "logger.info( 'Working with dataset: %s' % dataset )\n",
    "pos_dataset_fname = 'RF00005.fa'\n",
    "neg_dataset_fname = 'mixed.fa'\n",
    "\n",
    "pos_dataset_fname = 'RF00162.fa'\n",
    "neg_dataset_fname = 'RF01725.fa'\n",
    "\n",
    "percentages=[.08,.2,.4,.6,.8,.95]\n",
    "percentages=[.07,0.1,0.15,0.2]\n",
    "percentages=[.07,.1]\n",
    "\n",
    "\n",
    "# set size to 900 in production\n",
    "original_repetitions,\\\n",
    "original_sample_repetitions,\\\n",
    "sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                              neg_dataset_fname,\n",
    "                              size=100,\n",
    "                              percentages=percentages,\n",
    "                              n_repetitions=6, # ORIG = 10\n",
    "                              train_test_split=0.7)\n",
    "#save and display results\n",
    "result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions) \n",
    "\n",
    "\n",
    "percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\n",
    "plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "\n",
    "print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''time\n",
    "for dataset in dataset_names:\n",
    "    #logging\n",
    "    logger = logging.getLogger()\n",
    "    if True:\n",
    "        logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "    else:\n",
    "        logger_fname = None\n",
    "    configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "    \n",
    "    #main \n",
    "    start=time()\n",
    "    print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "    logger.info( 'Working with dataset: %s' % dataset )\n",
    "    pos_dataset_fname = \"RF00005.fa\"\n",
    "    neg_dataset_fname = 'mixed.fa\n",
    "\n",
    "    percentages=[.05,.2,.4,.6,.8,.95]\n",
    "    percentages=[.05,.2]\n",
    "\n",
    "    original_repetitions,\\\n",
    "    original_sample_repetitions,\\\n",
    "    sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                                  neg_dataset_fname,\n",
    "                                  size=400,\n",
    "                                  percentages=percentages,\n",
    "                                  n_repetitions=3,\n",
    "                                  train_test_split=0.7)\n",
    "    #save and display results\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions)    \n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "    \n",
    "    print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display\n",
    "'''\n",
    "for dataset in dataset_names:\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "# we always want a test and a train set to omou\n",
    "def get_seq_tups(fname,size,sizeb):\n",
    "    kram = fasta_to_sequence(\"../toolsdata/\"+fname)\n",
    "    graphs=[g for g in kram]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size],graphs[size:size+sizeb]\n",
    "\n",
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions): # note that the var names are not real anymore.\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    FONTSIZE=20\n",
    "    ws = .3\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    ax = plt.subplot() \n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(20)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample+orig')\n",
    "\n",
    "    # testing to plot some dots\n",
    "    global similarity_scores\n",
    "    plt.plot(percentages,similarity_scores,'bo')\n",
    "    \n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.xlim(5,20)\n",
    "    plt.ylim(0.0,1.005)\n",
    "    plt.title(dataset+'\\n',fontsize=20)\n",
    "    plt.legend(loc='lower right',fontsize=18)\n",
    "    plt.ylabel('ROC AUC',fontsize=18)\n",
    "    plt.xlabel('Training set size per family',fontsize=18)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)\n",
    "\n",
    "#load(\"DATAS\")\n",
    "#plot(\"RF00162 vs RF00005 learning curve\", [30,70], [[.30,.30],[.20,.20]] , [[.40,.40],[.30,.30]],[[.70,.35],[.25,.25]])\n",
    "import random\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "from graphlearn.estimator import Wrapper as estimatorwrapper\n",
    "import graphlearn.utils.draw as draw\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def fit_sample(graphs, random_state=random.random()):\n",
    "    '''\n",
    "    graphs -> more graphs\n",
    "    '''\n",
    "    graphs = list(graphs)\n",
    "    estimator=estimatorwrapper( nu=.5, cv=2, n_jobs=-1)\n",
    "    sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                                thickness_list=[2], \n",
    "                                min_cip_count=1, \n",
    "                                min_interface_count=2, \n",
    "                                preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                                postprocessor=rna.PostProcessor(),\n",
    "                                estimator=estimator\n",
    "                                #feasibility_checker=feasibility\n",
    "                               )\n",
    "    sampler.fit(graphs,grammar_n_jobs=4,grammar_batch_size=1)\n",
    "    graphs = [ b for a ,b in graphs  ]\n",
    "    graphs = sampler.sample(graphs,\n",
    "                            n_samples=3,\n",
    "                            batch_size=1,\n",
    "                            n_steps=50,\n",
    "                            n_jobs=4,\n",
    "                            quick_skip_orig_cip=True,\n",
    "                            probabilistic_core_choice=True,\n",
    "                            burnin=10,\n",
    "                            improving_threshold=0.3,\n",
    "                            improving_linear_start=0.2,\n",
    "                            max_size_diff=20,\n",
    "                            accept_min_similarity=0.65,\n",
    "                            select_cip_max_tries=30,\n",
    "                            keep_duplicates=False,\n",
    "                            include_seed=False,\n",
    "                            backtrack=2,\n",
    "                            monitor=False)\n",
    "    result=[]\n",
    "    for graphlist in graphs:\n",
    "        result+=graphlist\n",
    "    # note that this is a list [('',sequ),..]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "#  ok erstmal ueber alle x values, ne\n",
    "size_test=20\n",
    "dataset_a='RF00005.fa'\n",
    "dataset_a='RF01725.fa'\n",
    "dataset_b='RF00162.fa'\n",
    "sizes=[7,8,9,10,11,12,13,14,15]\n",
    "sizes=[7,8]\n",
    "repeats=1\n",
    "\n",
    "# calc everything\n",
    "def get_results():\n",
    "    li = [ get_datapoint(size) for size in sizes ]\n",
    "    # transpose , should work OO \n",
    "    print 'li:',li\n",
    "    return [list(i) for i in zip(*li)]\n",
    "\n",
    "from graphlearn import sumsim\n",
    "# calc for one \"size\", go over repeats\n",
    "def get_datapoint(size):\n",
    "    ra=[]\n",
    "    rb=[]\n",
    "    rab=[]\n",
    "    similarities=[]\n",
    "    global similarity_scores\n",
    "    \n",
    "    for rep in range(repeats):\n",
    "        train_a,test_a = get_seq_tups(dataset_a,size,size_test)\n",
    "        train_b,test_b = get_seq_tups(dataset_b,size,size_test)\n",
    "        a,b,ab,similarity = evaluate_point(train_a,train_b,test_a,test_b)\n",
    "        ra.append(a)\n",
    "        rab.append(ab)\n",
    "        rb.append(b)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    similarity_scores.append( (sum(similarities)/float(len(similarities))))\n",
    "    return ra,rb,rab\n",
    "\n",
    "\n",
    "def evaluate_point(train_a,train_b,test_a,test_b):\n",
    "    res=[]\n",
    "    res.append(  test(deepcopy(train_a),deepcopy(train_b),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    train_aa = fit_sample(train_a)\n",
    "    train_bb = fit_sample(train_b)\n",
    "    \n",
    "    eins=sumsim.calcsimset(deepcopy(train_aa),deepcopy(train_a))   \n",
    "    zwei=sumsim.calcsimset(deepcopy(train_bb),deepcopy(train_b))   \n",
    "    drei = (eins+zwei)/2.0\n",
    "    res.append(  test(deepcopy(train_aa),deepcopy(train_bb),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(  test(deepcopy(train_a)+deepcopy(train_aa),deepcopy(train_b)+train_bb,deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(drei)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "### just evaluate the stuff\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from eden.path import Vectorizer\n",
    "\n",
    "def train_esti(neg,pos):\n",
    "        v=Vectorizer()\n",
    "        matrix=v.transform(neg+pos)\n",
    "        res=SGDClassifier(shuffle=True)\n",
    "        res.fit(matrix, np.asarray(  [-1]*len(neg)+[1]*len(pos)  ) )\n",
    "        return res\n",
    "\n",
    "def eva(esti,ne,po):\n",
    "    v=Vectorizer()\n",
    "    matrix=v.transform(ne)\n",
    "    correct= sum(  [1 for res in esti.predict(matrix) if res == -1] ) \n",
    "    matrix2=v.transform(po)            \n",
    "    correct+= sum(  [1 for res in esti.predict(matrix2) if res == 1] )\n",
    "    return correct\n",
    "\n",
    "def test(a,b,ta,tb):\n",
    "    est=train_esti(a,b)\n",
    "    correct=eva(est,ta,tb)\n",
    "    return correct/float(size_test*2) # fraction correct\n",
    "    \n",
    "\n",
    "global similarity_scores\n",
    "similarity_scores=[]\n",
    "r=get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot('somename', sizes, *r)\n",
    "\n",
    "print similarity_scores\n",
    "print sizes\n",
    "print r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def sim(s1,s2):\n",
    "    l = float( max(len(s1),len(s2))) \n",
    "    lp = l - float(levenshtein(s1,s2))\n",
    "    return lp/l \n",
    "\n",
    "\n",
    "print 'testing sim eq', sim(s1[0],s1[0])\n",
    "print 'testing sim dif', sim(s2[0],s1[0])\n",
    "\n",
    "s1=['asdasd','asdasd','abc']\n",
    "s2=['zxczxc','asdasd','abc']\n",
    "\n",
    "\n",
    "def simsum(a,b,del_diag=False):\n",
    "    res=0.0\n",
    "    for i, ea in enumerate(a):\n",
    "        for j, eb in enumerate(b):\n",
    "            if del_diag and i==j:\n",
    "                continue\n",
    "            res+=simmilarity(ea,eb)\n",
    "    return res\n",
    "\n",
    "\n",
    "print 'testing simsum eq',simsum(s1,s1,True)\n",
    "print 'testing simsum neq',simsum(s2,s1)\n",
    "\n",
    "import math\n",
    "def calcsimset(a,b):\n",
    "    print 'calcsimset'\n",
    "    ab=simsum(s1,s2,False)\n",
    "    aa=simsum(a,a,False) \n",
    "    bb=simsum(b,b,False)\n",
    "    print ab,aa,bb\n",
    "    cc=aa*bb\n",
    "    print cc\n",
    "    print ab/math.sqrt(cc)\n",
    "\n",
    "    \n",
    "calcsimset(s1,s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graphlearn import sumsim\n",
    "print sumsim.__file__\n",
    "s1=['asdasd','asdasd','abc']\n",
    "s2=['zxczxc','asdasd','abc']\n",
    "sumsim.calcsimset(s1,s2)\n",
    "sumsim.similarity_mean(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "s1 = [('', 'CUCUUAUUGAGAGCGGUGGAGGGACUGGCCCUGUGAAACCCGGCAACCUUCAAACGAAAUGUUUGAAACGGUGCUAAUACCUGCAAAACGAAUGUUUUGCAUAAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGACAGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGAAAGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGAAACGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'AGCUCAUCCAGAGGGGCAGAGGGAAACGGCCCGAUGAAGCCCCGGCAACCCUCCAGUCGGUACUCGUAGGUCACUGAUUAUGAUAGGGAAGGUGCCAAAUCCGUCUCACGGCGAGAUGCGUCGUGAGGAAGAUGAGGA'), ('', 'UGCUUAUCUAGAGUGGCGGAGGGAAACGGCCCUUUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAUUCCAGACAGAUGAGGA'), ('', 'UUCUUAUCAAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCUUUUGGCAAAAUCUAAGCCUGAAAGAUGAGAA'), ('', 'CUUUUAUCCAGAGAUGGCGGAGGGACAGGCCCGAAGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('', 'CUUUUAUCCAGAGAUGGCGGAGGGAAAGGCCCGAAGAAGCCCAGCAACCUCUUCGUAACGAAGAAAGGUGCCAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('', 'AGCUUAUCGAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCCAUCCCGAAUAUUCGGGAAUAGAUGAGCG')] \n",
    "s2 = [('ACEZ01000126.1/65345-65190', 'AGCUCAUCCAGAGGGGCAGAGGGAAACGGCCCGAUGAAGCCCCGGCAACCCUCCAGUCGGUACUCGUAGGUCACUGGCGACCACUUCGCGAGGCUCCCGACUAGGGAAGGUGCCAAAUCCGUCUCACGGCGAGAUGCGUCGUGAGGAAGAUGAGGA'), ('AP008934.1/1011112-1011223', 'CUCUUAUCCUGAGUGGCGGAGGGACAUGGACCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('AAVL02000036.1/100921-100817', 'CUCUUAUUAAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACGGCAACCCCCGAUUAUGAUGGAAGGUGCCCACCGGAGCAAUGCAAUAUUGAUCAAUAAGAG'), ('AE017225.1/4074580-4074471', 'CUCUUAUUGAGAGCGGUGGAGGGAAAGGCCCUGUGAAACCCGGCAACCUUCAAACGAAAUGUUUGAAACGGUGCUAAUACCUGCAAAACGAAUGUUUUGCAUAAUAAGAG'), ('ABDQ01000003.1/211832-211918', 'UGCUUAUCUAGAGUGGCGGAGGGACUGGCCCUUUGAAGCCCAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCAGACAGAUGAGGA'), ('AP006627.1/3008449-3008342', 'CUUUUAUCCAGAGAUGGCGGAGGGACAGGCCCGAAGAAGCCCAGCAACCAACACGUAACGUGUAAAGGUGCUAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('AAXV01000005.1/126573-126679', 'UUCUUAUCAAGAGAGACGGAGGGAUCGGCCCGAUGAAGUCUCAGCAACCAGCUCAAUCAGUAUGGUGCUAAUUCCUUUUGGCAAAAUCUAAGCCUGAAAGAUGAGAA'), ('AAXU02000001.1/3185191-3185093', 'AGCUUAUCGAGAAAGACUGAGGGAAGGGCCCGACGACGUCUUAGCAACCUGUAACCAAGGUGCUAAUUCCCAUCCCGAAUAUUCGGGAAUAGAUGAGCG')]\n",
    "\n",
    "\n",
    "from Valium import sumsim as ss\n",
    "print ss.__file__\n",
    "#sumsim.calcsimset(s1,s2)\n",
    "#ss.score(s1,s2)\n",
    "a,b = ss.vectorize(s1,s2)\n",
    "dist= ss.compdistr(a,b)\n",
    "print dist\n",
    "sim = ss.simset(a,b)\n",
    "print 'sim',sim\n",
    "print dist-sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datapoint(size):\n",
    "    ra=[]\n",
    "    rb=[]\n",
    "    rab=[]\n",
    "    similarities=[]\n",
    "    global similarity_scores\n",
    "    for rep in range(repeats):\n",
    "\n",
    "\n",
    "        a,b,ab,similarity = evaluate_point(size)\n",
    "        ra.append(a)\n",
    "        rab.append(ab)\n",
    "        rb.append(b)\n",
    "        similarities.append(similarity)\n",
    "        \n",
    "    similarity_scores.append( \n",
    "        (sum(similarities)/float(len(similarities)))\n",
    "        )\n",
    "    return ra,rb,rab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_point(size):\n",
    "    res=[]\n",
    "\n",
    "    train_aa,train_a,test_a = get_trainthings(size,dataset_a)\n",
    "    train_bb,train_b,test_b = get_trainthings(size,dataset_b)\n",
    "\n",
    "\n",
    "    res.append(  \n",
    "        test(deepcopy(train_a),deepcopy(train_b),deepcopy(test_a),deepcopy(test_b)) \n",
    "    )\n",
    "    eins=sumsim.simset(deepcopy(train_aa),deepcopy(train_a))\n",
    "    zwei=sumsim.simset(deepcopy(train_bb),deepcopy(train_b)) \n",
    "    drei = (eins+zwei)/2.0\n",
    "    res.append(  test(deepcopy(train_aa),deepcopy(train_bb),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(  test(deepcopy(train_a)+deepcopy(train_aa),deepcopy(train_b)+train_bb,deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(drei)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import curve\n",
    "\n",
    "sizes = [20, 25]\n",
    "result = [[[0.95], [1.0]], [[0.975], [0.9]], [[0.95], [1.0]]]\n",
    "\n",
    "sizes = [20, 25]\n",
    "result = [[[1.0, 0.95, 1.0], [1.0, 0.975, 1.0]], [[0.775, 0.775, 0.925], [1.0, 1.0, 0.925]], [[0.975, 0.95, 0.975], [0.875, 0.975, 1.0]]]\n",
    "similarity_scores = [1.0297192402202902, 1.0271841248414073]\n",
    "curve.similarity_scores = similarity_scores \n",
    "\n",
    "result = [\n",
    "            [\n",
    "                [1.0, 1.0, 0.975, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 0.95, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 0.975], \n",
    "                [0.975, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0],\n",
    "                [1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [0.925, 0.95, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975], \n",
    "                [1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0], \n",
    "                [0.975, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0]], \n",
    "            [\n",
    "                [0.825, 1.0, 0.9, 1.0, 0.975, 0.825, 0.725, 0.6, 1.0], \n",
    "                [0.675, 0.9, 0.775, 1.0, 0.85, 1.0, 0.8, 0.85, 0.975], \n",
    "                [1.0, 1.0, 0.975, 0.975, 0.9, 0.975, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0], \n",
    "                [1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0], \n",
    "                [0.975, 0.975, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0], \n",
    "                [1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975]], \n",
    "           [\n",
    "                [0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0], \n",
    "                [1.0, 1.0, 0.95, 0.975, 0.975, 1.0, 0.95, 1.0, 1.0], \n",
    "                [1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0], \n",
    "                [0.975, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "        ]\n",
    "similarity_scores = [1.0232968855718843, 1.0007455908832672, 0.99180448653574027, 0.98595714838649307, 0.9916254516732721, 0.98422063083413702, 0.98257742970417483]\n",
    "\n",
    "result = [[[1.0, 0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0], [0.95, 1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 0.975, 1.0], [1.0, 0.925, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975], [1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975]], [[0.975, 0.975, 1.0, 0.825, 0.925, 0.925, 0.95, 1.0, 0.975], [1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 0.95, 1.0, 0.975], [1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975], [1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0], [0.975, 0.95, 0.975, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975], [1.0, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 0.925], [1.0, 1.0, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 0.975]], [[1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.85, 1.0, 1.0], [1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95], [1.0, 1.0, 0.825, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0], [0.975, 1.0, 0.975, 0.975, 0.875, 1.0, 0.975, 1.0, 0.975], [1.0, 1.0, 1.0, 0.975, 1.0, 0.95, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]]\n",
    "similarity_scores = [1.0168101311663511, 1.0150377354846287, 1.0009668568440384, 1.0013156444262343, 0.99809664727147385, 0.99622003788844737, 0.99512742871661353]\n",
    "\n",
    "numgr=[20 ,25 ,30, 35, 40, 45, 50]\n",
    "\n",
    "result = [[[0.99, 0.985, 0.985, 0.99, 0.99, 0.985, 0.985], [0.955, 0.985, 1.0, 0.99, 0.97, 0.975, 0.975], [0.985, 0.975, 0.95, 0.965, 0.965, 0.985, 0.96], [0.975, 0.955, 0.975, 0.995, 0.98, 0.975, 0.995], [0.99, 0.99, 0.99, 0.985, 0.98, 0.99, 0.985], [0.98, 0.965, 0.975, 0.98, 0.97, 0.985, 0.99], [0.995, 0.975, 0.98, 0.99, 0.995, 0.985, 0.995]], [[0.995, 0.985, 0.835, 0.78, 0.91, 0.965, 0.975], [0.995, 0.93, 0.985, 0.99, 0.98, 0.985, 0.98], [0.965, 0.845, 0.98, 0.95, 0.925, 0.975, 0.985], [0.975, 0.985, 0.975, 0.97, 0.955, 0.985, 0.985], [0.995, 0.99, 0.995, 0.985, 0.99, 0.98, 0.99], [0.99, 1.0, 0.985, 0.99, 0.995, 0.98, 0.995], [0.99, 0.985, 0.945, 0.945, 0.985, 0.99, 0.985]], [[0.99, 0.995, 1.0, 0.995, 0.99, 0.995, 1.0], [1.0, 0.98, 0.975, 0.945, 0.99, 1.0, 0.98], [0.985, 0.985, 0.975, 0.995, 0.98, 0.975, 0.97], [0.995, 0.985, 0.985, 0.985, 0.98, 0.975, 0.975], [0.985, 0.995, 0.985, 0.995, 0.995, 0.995, 0.98], [0.985, 0.995, 0.995, 0.99, 0.98, 0.99, 0.995], [0.995, 0.99, 0.995, 0.99, 0.995, 0.98, 0.985]]]\n",
    "similarity_scores = [1.009134975438486, 1.0020476673182956, 0.99512728715033838, 0.9902838600590177, 0.98878387701645598, 0.98004841660025499, 0.97223030477865113]\n",
    "\n",
    "curve.similarity_scores=similarity_scores\n",
    "curve.plot(\"%s vs %s discriminative performance\" % (curve.dataset_a[:-3],curve.dataset_b[:-3]),numgr,*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=np.array(range(4))\n",
    "l.tolist()*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikea/.local/lib/python2.7/site-packages/matplotlib/__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeats 2 ; sizes = [20, 30] ; argparam =1 \n",
      ". k k k k [[[0.51949667082361095, 0.29774344044260181], [0.43141557542285591, 0.168805434295172]], [[1.0084572756298387, 1.0168158563891236], [1.0006380849626419, 1.0032009449614399]]]\n",
      "[20 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikea/.local/lib/python2.7/site-packages/matplotlib/font_manager.py:1288: UserWarning: findfont: Font family [u'Arial'] not found. Falling back to Bitstream Vera Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5ff88f090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGMCAYAAAD0nYndAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEcms/w9Vf7D8wqirFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5fccabc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import oneclasscurve  as occ\n",
    "sizes=[20,30]\n",
    "a,b = occ.get_results(repeats=2,sizes=sizes,njobs=4,argparam=1)\n",
    "occ.plot('123',sizes,a,b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import oneclasscurve  as occ\n",
    "occ.plot('123',sizes,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array([[ 0.09634476 , 0.90365524],\n",
    " [ 0.06088005,  0.93911995],\n",
    " [ 0.07065094 , 0.92934906],\n",
    " [ 0.04671271,  0.95328729],\n",
    " [ 0.02970209 , 0.97029791],\n",
    " [ 0.29515478 , 0.70484522],\n",
    " [ 0.86338974 , 0.13661026],\n",
    " [ 0.80168559 , 0.19831441],\n",
    " [ 0.80968646 , 0.19031354],\n",
    " [ 0.12463197  ,0.87536803],\n",
    " [ 0.1517372   ,0.8482628 ],\n",
    " [ 0.34249768,  0.65750232],\n",
    " [ 0.07255634,  0.92744366],\n",
    " [ 0.02922214,  0.97077786],\n",
    " [ 0.77822639,  0.22177361],\n",
    " [ 0.81886221,  0.18113779],\n",
    " [ 0.16694517,  0.83305483],\n",
    " [ 0.12744298,  0.87255702],\n",
    " [ 0.09078483,  0.90921517],\n",
    " [ 0.04598973,  0.95401027],\n",
    " [ 0.80762083 , 0.19237917],\n",
    " [ 0.03582149 , 0.96417851],\n",
    " [ 0.82493818  ,0.17506182],\n",
    " [ 0.07749642 , 0.92250358],\n",
    " [ 0.52502072 , 0.47497928],\n",
    " [ 0.20059041 , 0.79940959],\n",
    " [ 0.54677554  ,0.45322446],\n",
    " [ 0.75185612  ,0.24814388],\n",
    " [ 0.72276445 , 0.27723555],\n",
    " [ 0.78464842 , 0.21535158],\n",
    " [ 0.41365199 , 0.58634801],\n",
    " [ 0.09839525 , 0.90160475],\n",
    " [ 0.03955736  ,0.96044264],\n",
    " [ 0.39204652  ,0.60795348],\n",
    " [ 0.58669915  ,0.41330085],\n",
    " [ 0.09951188  ,0.90048812],\n",
    " [ 0.69697943  ,0.30302057],\n",
    " [ 0.7775214   ,0.2224786 ]])\n",
    "\n",
    "print a[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

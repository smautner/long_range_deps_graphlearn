{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikea/.local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/ikea/miniconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ikea/miniconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import eden\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import Sampler as GraphLearnSampler\n",
    "from eden.util import fit,estimate\n",
    "from eden.path import Vectorizer\n",
    "import random\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "import random\n",
    "'''\n",
    "GET RNA DATA\n",
    "'''\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import itertools\n",
    "\n",
    "def rfam_uri(family_id):\n",
    "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "def rfam_uri(family_id):\n",
    "    return '%s.fa'%(family_id)\n",
    " \n",
    "\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "def get_sequences_with_names(filename='RF00005.fa'):\n",
    "    sequences = fasta_to_sequence(\"../toolsdata/\"+filename)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_graphs(fname,size):\n",
    "    graphs=[g for g in get_sequences_with_names(fname)]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size]\n",
    "\n",
    "# formerly:\n",
    "#get_graphs(dataset_fname, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "from graphlearn.estimator import Wrapper as estimatorwrapper\n",
    "import graphlearn.utils.draw as draw\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def fit_sample(graphs, random_state=random.random()):\n",
    "    '''\n",
    "    graphs -> more graphs\n",
    "    '''\n",
    "    graphs = list(graphs)\n",
    "    estimator=estimatorwrapper( nu=.5, cv=2, n_jobs=-1)\n",
    "    sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                                thickness_list=[2], \n",
    "                                min_cip_count=1, \n",
    "                                min_interface_count=2, \n",
    "                                preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                                postprocessor=rna.PostProcessor(),\n",
    "                                estimator=estimator\n",
    "                                #feasibility_checker=feasibility\n",
    "                               )\n",
    "    sampler.fit(graphs,grammar_n_jobs=4,grammar_batch_size=1)\n",
    "    \n",
    "    \n",
    "    logger.info('graph grammar stats:')\n",
    "    dataset_size, interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#instances:%d   #interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (dataset_size, interface_counts, core_counts, cip_counts))\n",
    "    \n",
    "    \n",
    "    graphs = [ b for a ,b in graphs  ]\n",
    "    \n",
    "    graphs = sampler.sample(graphs,\n",
    "                            n_samples=3,\n",
    "                            batch_size=1,\n",
    "                            n_steps=50,\n",
    "                            n_jobs=4,\n",
    "                            quick_skip_orig_cip=True,\n",
    "                            probabilistic_core_choice=True,\n",
    "                            burnin=10,\n",
    "                            improving_threshold=0.9,\n",
    "                            improving_linear_start=0.3,\n",
    "                            max_size_diff=20,\n",
    "                            accept_min_similarity=0.65,\n",
    "                            select_cip_max_tries=30,\n",
    "                            keep_duplicates=False,\n",
    "                            include_seed=False,\n",
    "                            backtrack=10,\n",
    "                            monitor=False)\n",
    "    result=[]\n",
    "    for graphlist in graphs:\n",
    "        result+=graphlist\n",
    "    # note that this is a list [('',sequ),..]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(pos_original, neg_original,\n",
    "                     pos_sampled, neg_sampled,\n",
    "                     pos_test, neg_test,\n",
    "                     random_state=42):\n",
    "    '''\n",
    "    pos + neg orig+sampled testsets -> orig_roc , sampled_roc, augmented_roc\n",
    "    '''\n",
    "    \n",
    "    # create graph sets...orig augmented and sampled\n",
    "    pos_orig,pos_orig_ = tee(pos_original)\n",
    "    neg_orig,neg_orig_ = tee(neg_original)\n",
    "    \n",
    "    pos_sampled, pos_sampled_ = tee(pos_sampled)\n",
    "    neg_sampled, neg_sampled_ = tee(neg_sampled)\n",
    "    \n",
    "    pos_augmented = chain(pos_orig_,pos_sampled_)\n",
    "    neg_augmented = chain(neg_orig_,neg_sampled_)\n",
    "\n",
    "    predictive_performances = []\n",
    "    for desc,pos_train,neg_train in [('original',pos_orig, neg_orig),\n",
    "                                     ('sample',pos_sampled,neg_sampled),\n",
    "                                     ('original+sample',pos_augmented, neg_augmented)]:\n",
    "        pos_train,pos_train_ = tee(pos_train)\n",
    "        neg_train,neg_train_ = tee(neg_train)\n",
    "        pos_size=sum(1 for x in pos_train_)\n",
    "        neg_size=sum(1 for x in neg_train_)\n",
    "\n",
    "        logger.info( \"-\"*80)\n",
    "        logger.info('working on %s'%(desc))\n",
    "        logger.info('training set sizes: #pos: %d #neg: %d'%(pos_size, neg_size))\n",
    "\n",
    "        if pos_size == 0 or neg_size == 0:\n",
    "            logger.info('WARNING: empty dataset')\n",
    "            predictive_performances.append(0)            \n",
    "        else:\n",
    "            start=time()\n",
    "            pos_test,pos_test_ = tee(pos_test)\n",
    "            neg_test,neg_test_ = tee(neg_test)\n",
    "            \n",
    "            local_estimator = fit(pos_train, neg_train, Vectorizer(4), n_jobs=-1, n_iter_search=1)\n",
    "            apr, roc = estimate(pos_test_, neg_test_, local_estimator, Vectorizer(4))\n",
    "            predictive_performances.append(roc)\n",
    "            logger.info( 'elapsed: %.1f sec'%(time()-start))\n",
    "    return predictive_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pos_fname, neg_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs_pos = get_graphs(pos_fname, size=size)\n",
    "    graphs_neg = get_graphs(neg_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    pos_train_global,pos_test_global = random_bipartition_iter(graphs_pos,train_test_split,random_state=random.random()*1000)\n",
    "    neg_train_global,neg_test_global = random_bipartition_iter(graphs_neg,train_test_split,random_state=random.random()*1000)\n",
    "\n",
    "\n",
    "    original_repetitions = []\n",
    "    original_sample_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random_state = int(313379*percentage+repetition) \n",
    "            random.seed(random_state)\n",
    "            pos_train_global,pos_train_global_ = tee(pos_train_global)\n",
    "            neg_train_global,neg_train_global_ = tee(neg_train_global)\n",
    "            pos_test_global,pos_test_global_ = tee(pos_test_global)\n",
    "            neg_test_global,neg_test_global_ = tee(neg_test_global)\n",
    "\n",
    "            # use shuffled list to create test and sample set\n",
    "            pos,pos_reminder = random_bipartition_iter(pos_train_global_,percentage)\n",
    "            pos,pos_ = tee(pos)\n",
    "            neg,neg_reminder = random_bipartition_iter(neg_train_global_,percentage)\n",
    "            neg,neg_ = tee(neg)\n",
    "\n",
    "            #sample independently from the 2 classes\n",
    "            logger.info('Positive')\n",
    "            sampled_pos = fit_sample(pos_, random_state=random_state)\n",
    "            logger.info('Negative')\n",
    "            sampled_neg = fit_sample(neg_, random_state=random_state)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            logger.info( \"=\"*80)\n",
    "            logger.info( 'repetition: %d/%d'%(repetition+1, n_repetitions))\n",
    "            logger.info( \"training percentage:\"+str(percentage))\n",
    "            perf_orig,\\\n",
    "            perf_samp,\\\n",
    "            perf_orig_samp = fit_and_evaluate(pos,neg,\n",
    "                                              sampled_pos,sampled_neg,\n",
    "                                              pos_test_global_,neg_test_global_)\n",
    "            logger.info( 'Time elapsed for full repetition: %.1f sec'%((time()-start)))\n",
    "            originals.append(perf_orig)\n",
    "            originals_samples.append(perf_orig_samp)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        original_sample_repetitions.append(originals_samples)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, original_sample_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    FONTSIZE=20\n",
    "    ws = 1\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    ax = plt.subplot() \n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(20)\n",
    "    \n",
    "    \n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original+sample')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.xlim(2,15)\n",
    "    #plt.ylim(0.99,1.005)\n",
    "    plt.ylim(0.0,1.005)\n",
    "    plt.title(dataset+'\\n',fontsize=20)\n",
    "    plt.legend(loc='lower right',fontsize=18)\n",
    "    plt.ylabel('ROC AUC',fontsize=18)\n",
    "    plt.xlabel('Training set size per family',fontsize=18)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)\n",
    "\n",
    "#load(\"DATAS\")\n",
    "#plot(\"RF00162 vs RF00005 learning curve\", percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions):\\n    with open(result_fname,'w') as f:\\n        f.write('dataset sizes list:\\n')\\n        for perc in percentages:\\n            f.write('%s '% perc)\\n        f.write('\\n')\\n        f.write('AUC scores:\\n')\\n        for repetitions in original_repetitions,original_sample_repetitions,sample_repetitions:\\n            f.write('%s\\n' % len(repetitions))\\n            for repetition in repetitions:\\n                for auc in repetition:\\n                    f.write('%s ' % auc)\\n                f.write('\\n')\\n    \\ndef load_results(result_fname):\\n    with open(result_fname) as f:\\n        comment = next(f)\\n        line = next(f)\\n        percentages = [float(x) for x in line.split()]\\n        comment = next(f)\\n\\n        original_repetitions = []\\n        size = int(next(f))\\n        for i in range(size):\\n            line = next(f)\\n            repetition = [float(x) for x in line.split()]\\n            original_repetitions.append(repetition)\\n\\n        original_sample_repetitions = []\\n        size = int(next(f))\\n        for i in range(size):\\n            line = next(f)\\n            repetition = [float(x) for x in line.split()]\\n            original_sample_repetitions.append(repetition)\\n\\n\\n        sample_repetitions = []\\n        size = int(next(f))\\n        for i in range(size):\\n            line = next(f)\\n            repetition = [float(x) for x in line.split()]\\n            sample_repetitions.append(repetition)\\n            \\n    return percentages, original_repetitions,original_sample_repetitions,sample_repetitions\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions):\n",
    "    with open(result_fname,'w') as f:\n",
    "        f.write('dataset sizes list:\\n')\n",
    "        for perc in percentages:\n",
    "            f.write('%s '% perc)\n",
    "        f.write('\\n')\n",
    "        f.write('AUC scores:\\n')\n",
    "        for repetitions in original_repetitions,original_sample_repetitions,sample_repetitions:\n",
    "            f.write('%s\\n' % len(repetitions))\n",
    "            for repetition in repetitions:\n",
    "                for auc in repetition:\n",
    "                    f.write('%s ' % auc)\n",
    "                f.write('\\n')\n",
    "    \n",
    "def load_results(result_fname):\n",
    "    with open(result_fname) as f:\n",
    "        comment = next(f)\n",
    "        line = next(f)\n",
    "        percentages = [float(x) for x in line.split()]\n",
    "        comment = next(f)\n",
    "\n",
    "        original_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_repetitions.append(repetition)\n",
    "\n",
    "        original_sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_sample_repetitions.append(repetition)\n",
    "\n",
    "\n",
    "        sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            sample_repetitions.append(repetition)\n",
    "            \n",
    "    return percentages, original_repetitions,original_sample_repetitions,sample_repetitions\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experimental pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot(\"RF00162 vs RF01725\", percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "\n",
    "#print '%s_predictive_performance_of_samples.data'%dataset\n",
    "#!cat \"RF00162 vs RF00005 training curve_predictive_performance_of_samples.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\n",
    "#plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\n#special case: bursi\\n\\ndataset='RF00162 vs RF00005 training curve'\\n#logging\\nlogger = logging.getLogger()\\nif True:\\n    logger_fname = '%s_predictive_performance_of_samples.log'%dataset\\nelse:\\n    logger_fname = None\\nconfigure_logging(logger,verbosity=1, filename=logger_fname)\\n\\n#main \\nstart=time()\\nprint( 'Working with dataset: %s' % dataset )\\n\\nlogger.info( 'Working with dataset: %s' % dataset )\\npos_dataset_fname = 'RF00005.fa'\\nneg_dataset_fname = 'mixed.fa'\\n\\npos_dataset_fname = 'RF00162.fa'\\nneg_dataset_fname = 'RF01725.fa'\\n\\npercentages=[.08,.2,.4,.6,.8,.95]\\npercentages=[.07,0.1,0.15,0.2]\\npercentages=[.07,.1]\\n\\n\\n# set size to 900 in production\\noriginal_repetitions,original_sample_repetitions,sample_repetitions = evaluate(pos_dataset_fname,\\n                              neg_dataset_fname,\\n                              size=100,\\n                              percentages=percentages,\\n                              n_repetitions=6, # ORIG = 10\\n                              train_test_split=0.7)\\n#save and display results\\nresult_fname='%s_predictive_performance_of_samples.data'%dataset\\nsave_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions) \\n\\n\\npercentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\\nplot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\\n\\nprint('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "#special case: bursi\n",
    "\n",
    "dataset='RF00162 vs RF00005 training curve'\n",
    "#logging\n",
    "logger = logging.getLogger()\n",
    "if True:\n",
    "    logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "else:\n",
    "    logger_fname = None\n",
    "configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "\n",
    "#main \n",
    "start=time()\n",
    "print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "logger.info( 'Working with dataset: %s' % dataset )\n",
    "pos_dataset_fname = 'RF00005.fa'\n",
    "neg_dataset_fname = 'mixed.fa'\n",
    "\n",
    "pos_dataset_fname = 'RF00162.fa'\n",
    "neg_dataset_fname = 'RF01725.fa'\n",
    "\n",
    "percentages=[.08,.2,.4,.6,.8,.95]\n",
    "percentages=[.07,0.1,0.15,0.2]\n",
    "percentages=[.07,.1]\n",
    "\n",
    "\n",
    "# set size to 900 in production\n",
    "original_repetitions,\\\n",
    "original_sample_repetitions,\\\n",
    "sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                              neg_dataset_fname,\n",
    "                              size=100,\n",
    "                              percentages=percentages,\n",
    "                              n_repetitions=6, # ORIG = 10\n",
    "                              train_test_split=0.7)\n",
    "#save and display results\n",
    "result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions) \n",
    "\n",
    "\n",
    "percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\n",
    "plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "\n",
    "print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time\\nfor dataset in dataset_names:\\n    #logging\\n    logger = logging.getLogger()\\n    if True:\\n        logger_fname = \\'%s_predictive_performance_of_samples.log\\'%dataset\\n    else:\\n        logger_fname = None\\n    configure_logging(logger,verbosity=1, filename=logger_fname)\\n    \\n    #main \\n    start=time()\\n    print( \\'Working with dataset: %s\\' % dataset )\\n\\n    logger.info( \\'Working with dataset: %s\\' % dataset )\\n    pos_dataset_fname = \"RF00005.fa\"\\n    neg_dataset_fname = \\'mixed.fa\\n\\n    percentages=[.05,.2,.4,.6,.8,.95]\\n    percentages=[.05,.2]\\n\\n    original_repetitions,    original_sample_repetitions,    sample_repetitions = evaluate(pos_dataset_fname,\\n                                  neg_dataset_fname,\\n                                  size=400,\\n                                  percentages=percentages,\\n                                  n_repetitions=3,\\n                                  train_test_split=0.7)\\n    #save and display results\\n    result_fname=\\'%s_predictive_performance_of_samples.data\\'%dataset\\n    save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions)    \\n    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\\n    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\\n    \\n    print(\\'Time elapsed: %s\\'%(datetime.timedelta(seconds=(time() - start))))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''time\n",
    "for dataset in dataset_names:\n",
    "    #logging\n",
    "    logger = logging.getLogger()\n",
    "    if True:\n",
    "        logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "    else:\n",
    "        logger_fname = None\n",
    "    configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "    \n",
    "    #main \n",
    "    start=time()\n",
    "    print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "    logger.info( 'Working with dataset: %s' % dataset )\n",
    "    pos_dataset_fname = \"RF00005.fa\"\n",
    "    neg_dataset_fname = 'mixed.fa\n",
    "\n",
    "    percentages=[.05,.2,.4,.6,.8,.95]\n",
    "    percentages=[.05,.2]\n",
    "\n",
    "    original_repetitions,\\\n",
    "    original_sample_repetitions,\\\n",
    "    sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                                  neg_dataset_fname,\n",
    "                                  size=400,\n",
    "                                  percentages=percentages,\n",
    "                                  n_repetitions=3,\n",
    "                                  train_test_split=0.7)\n",
    "    #save and display results\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions)    \n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "    \n",
    "    print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor dataset in dataset_names:\\n    result_fname='%s_predictive_performance_of_samples.data'%dataset\\n    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\\n    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "'''\n",
    "for dataset in dataset_names:\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "# we always want a test and a train set to omou\n",
    "def get_seq_tups(fname,size,sizeb):\n",
    "    kram = fasta_to_sequence(\"../toolsdata/\"+fname)\n",
    "    graphs=[g for g in kram]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size],graphs[size:size+sizeb]\n",
    "\n",
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions): # note that the var names are not real anymore.\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    FONTSIZE=20\n",
    "    ws = .3\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    ax = plt.subplot() \n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(20)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample+orig')\n",
    "\n",
    "    # testing to plot some dots\n",
    "    global similarity_scores\n",
    "    plt.plot(percentages,similarity_scores,'bo')\n",
    "    \n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.xlim(5,20)\n",
    "    plt.ylim(0.0,1.005)\n",
    "    plt.title(dataset+'\\n',fontsize=20)\n",
    "    plt.legend(loc='lower right',fontsize=18)\n",
    "    plt.ylabel('ROC AUC',fontsize=18)\n",
    "    plt.xlabel('Training set size per family',fontsize=18)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)\n",
    "\n",
    "#load(\"DATAS\")\n",
    "#plot(\"RF00162 vs RF00005 learning curve\", [30,70], [[.30,.30],[.20,.20]] , [[.40,.40],[.30,.30]],[[.70,.35],[.25,.25]])\n",
    "import random\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "from graphlearn.estimator import Wrapper as estimatorwrapper\n",
    "import graphlearn.utils.draw as draw\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def fit_sample(graphs, random_state=random.random()):\n",
    "    '''\n",
    "    graphs -> more graphs\n",
    "    '''\n",
    "    graphs = list(graphs)\n",
    "    estimator=estimatorwrapper( nu=.5, cv=2, n_jobs=-1)\n",
    "    sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                                thickness_list=[2], \n",
    "                                min_cip_count=1, \n",
    "                                min_interface_count=2, \n",
    "                                preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                                postprocessor=rna.PostProcessor(),\n",
    "                                estimator=estimator\n",
    "                                #feasibility_checker=feasibility\n",
    "                               )\n",
    "    sampler.fit(graphs,grammar_n_jobs=4,grammar_batch_size=1)\n",
    "    graphs = [ b for a ,b in graphs  ]\n",
    "    graphs = sampler.sample(graphs,\n",
    "                            n_samples=3,\n",
    "                            batch_size=1,\n",
    "                            n_steps=50,\n",
    "                            n_jobs=4,\n",
    "                            quick_skip_orig_cip=True,\n",
    "                            probabilistic_core_choice=True,\n",
    "                            burnin=10,\n",
    "                            improving_threshold=0.3,\n",
    "                            improving_linear_start=0.2,\n",
    "                            max_size_diff=20,\n",
    "                            accept_min_similarity=0.65,\n",
    "                            select_cip_max_tries=30,\n",
    "                            keep_duplicates=False,\n",
    "                            include_seed=False,\n",
    "                            backtrack=2,\n",
    "                            monitor=False)\n",
    "    result=[]\n",
    "    for graphlist in graphs:\n",
    "        result+=graphlist\n",
    "    # note that this is a list [('',sequ),..]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57605068  1.          0.03300492  0.15936184  0.        ]\n",
      " [ 0.57605068  1.          0.03300492  0.15936184  0.        ]\n",
      " [ 0.03615508  0.03300492  1.          0.          0.05555556]\n",
      " [ 0.12523577  0.15936184  0.          1.          0.        ]\n",
      " [ 0.          0.          0.05555556  0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-17:\n",
      "Process PoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "Process PoolWorker-16:\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    if self._accept(graph_manager, candidate_graph_manager):\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 869, in _sample_multi\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 869, in _sample_multi\n",
      "    return [self._sample(g) for g in graphlist]\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    return [self._sample(g) for g in graphlist]\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 415, in _sample\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 415, in _sample\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    if self._accept(graph_manager, candidate_graph_manager):\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 869, in _sample_multi\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 560, in _accept\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 560, in _accept\n",
      "    return [self._sample(g) for g in graphlist]\n",
      "    score_graph_new = self._score(graphman_new)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 412, in _sample\n",
      "    candidate_graph_manager = self._propose(graph_manager)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 612, in _propose\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 545, in _score\n",
      "    score_graph_new = self._score(graphman_new)\n",
      "    graphman2 = self._propose_graph(graphman)\n",
      "    graphmanager._score= self.estimatorobject.score(graphmanager,keep_vector=self.accept_min_similarity)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 545, in _score\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/estimator.py\", line 115, in score\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 655, in _propose_graph\n",
      "    graphmanager._score= self.estimatorobject.score(graphmanager,keep_vector=self.accept_min_similarity)\n",
      "    transformed_graph = self.vectorizer.transform_single(self.unwrap(graphmanager))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/estimator.py\", line 115, in score\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/graph.py\", line 317, in transform_single\n",
      "    transformed_graph = self.vectorizer.transform_single(self.unwrap(graphmanager))\n",
      "    new_graphmanager = self.postprocessor.re_transform_single(new_graph)\n",
      "    return self._convert_dict_to_sparse_matrix(self._transform(0, graph))\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/graph.py\", line 631, in _transform\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/estimator.py\", line 142, in unwrap\n",
      "    self._transform_vertex(graph, v, feature_list)\n",
      "    graph = graphmanager.graph().copy()\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/graph.py\", line 657, in _transform_vertex\n",
      "    self._transform_vertex_pair(graph, vertex_v, vertex_u, distance, feature_list)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 228, in graph\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 28, in re_transform_single\n",
      "    g= nx.disjoint_union(self._base_graph, self.abstract_graph())\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 141, in abstract_graph\n",
      "    return self.pp.re_transform_single(input)\n",
      "    self._abstract_graph = forgi.edge_parent_finder(abstract_graph, self._base_graph)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/forgi/__init__.py\", line 194, in edge_parent_finder\n",
      "    for n, d in graph.nodes(data=True):\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 93, in re_transform_single\n",
      "KeyboardInterrupt\n",
      "    trans = self.transform([sequence])[0]\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 110, in transform\n",
      "    structure,energy = self.NNmodel.transform_single(('fake',sequence))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 509, in transform_single\n",
      "    head,seq,stru,en = self.eden_rna_vectorizer._align_sequence_structure(s,neigh,structure_deletions=True)\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/RNA.py\", line 176, in _align_sequence_structure\n",
      "    out = sp.check_output(cmd, shell=True)\n",
      "  File \"/usr/lib/python2.7/subprocess.py\", line 567, in check_output\n",
      "    process = Popen(stdout=PIPE, *popenargs, **kwargs)\n",
      "  File \"/usr/lib/python2.7/subprocess.py\", line 711, in __init__\n",
      "    errread, errwrite)\n",
      "  File \"/usr/lib/python2.7/subprocess.py\", line 1235, in _execute_child\n",
      "    self.pid = os.fork()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# calc everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mget_datapoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# transpose , should work OO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'li:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36mget_datapoint\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_seq_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_seq_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mrab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36mevaluate_point\u001b[0;34m(train_a, train_b, test_a, test_b)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtrain_aa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtrain_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0meins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msumsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcsimset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_aa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-8f3286925d44>\u001b[0m in \u001b[0;36mfit_sample\u001b[0;34m(graphs, random_state)\u001b[0m\n\u001b[1;32m     93\u001b[0m                             monitor=False)\n\u001b[1;32m     94\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mgraphlist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mgraphlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# note that this is a list [('',sequ),..]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, graph_iter, probabilistic_core_choice, score_core_choice, max_size_diff, similarity, n_samples, proposal_probability, batch_size, n_jobs, target_orig_cip, n_steps, quick_skip_orig_cip, improving_threshold, improving_linear_start, accept_static_penalty, accept_min_similarity, select_cip_max_tries, burnin, backtrack, include_seed, keep_duplicates, monitor)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0msampled_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sample_multi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_graphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoni\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mnew_graph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoni\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "#  ok erstmal ueber alle x values, ne\n",
    "size_test=20\n",
    "dataset_a='RF00005.fa'\n",
    "dataset_a='RF01725.fa'\n",
    "dataset_b='RF00162.fa'\n",
    "sizes=[7,8,9,10,11,12,13,14,15]\n",
    "sizes=[7,8]\n",
    "repeats=1\n",
    "\n",
    "# calc everything\n",
    "def get_results():\n",
    "    li = [ get_datapoint(size) for size in sizes ]\n",
    "    # transpose , should work OO \n",
    "    print 'li:',li\n",
    "    return [list(i) for i in zip(*li)]\n",
    "\n",
    "from graphlearn import sumsim\n",
    "# calc for one \"size\", go over repeats\n",
    "def get_datapoint(size):\n",
    "    ra=[]\n",
    "    rb=[]\n",
    "    rab=[]\n",
    "    similarities=[]\n",
    "    global similarity_scores\n",
    "    \n",
    "    for rep in range(repeats):\n",
    "        train_a,test_a = get_seq_tups(dataset_a,size,size_test)\n",
    "        train_b,test_b = get_seq_tups(dataset_b,size,size_test)\n",
    "        a,b,ab,similarity = evaluate_point(train_a,train_b,test_a,test_b)\n",
    "        ra.append(a)\n",
    "        rab.append(ab)\n",
    "        rb.append(b)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    similarity_scores.append( (sum(similarities)/float(len(similarities))))\n",
    "    return ra,rb,rab\n",
    "\n",
    "\n",
    "def evaluate_point(train_a,train_b,test_a,test_b):\n",
    "    res=[]\n",
    "    res.append(  test(deepcopy(train_a),deepcopy(train_b),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    train_aa = fit_sample(train_a)\n",
    "    train_bb = fit_sample(train_b)\n",
    "    \n",
    "    eins=sumsim.calcsimset(deepcopy(train_aa),deepcopy(train_a))   \n",
    "    zwei=sumsim.calcsimset(deepcopy(train_bb),deepcopy(train_b))   \n",
    "    drei = (eins+zwei)/2.0\n",
    "    res.append(  test(deepcopy(train_aa),deepcopy(train_bb),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(  test(deepcopy(train_a)+deepcopy(train_aa),deepcopy(train_b)+train_bb,deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(drei)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "### just evaluate the stuff\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from eden.path import Vectorizer\n",
    "\n",
    "def train_esti(neg,pos):\n",
    "        v=Vectorizer()\n",
    "        matrix=v.transform(neg+pos)\n",
    "        res=SGDClassifier(shuffle=True)\n",
    "        res.fit(matrix, np.asarray(  [-1]*len(neg)+[1]*len(pos)  ) )\n",
    "        return res\n",
    "\n",
    "def eva(esti,ne,po):\n",
    "    v=Vectorizer()\n",
    "    matrix=v.transform(ne)\n",
    "    correct= sum(  [1 for res in esti.predict(matrix) if res == -1] ) \n",
    "    matrix2=v.transform(po)            \n",
    "    correct+= sum(  [1 for res in esti.predict(matrix2) if res == 1] )\n",
    "    return correct\n",
    "\n",
    "def test(a,b,ta,tb):\n",
    "    est=train_esti(a,b)\n",
    "    correct=eva(est,ta,tb)\n",
    "    return correct/float(size_test*2) # fraction correct\n",
    "    \n",
    "\n",
    "global similarity_scores\n",
    "similarity_scores=[]\n",
    "r=get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b39d1de2cda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'somename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "plot('somename', sizes, *r)\n",
    "\n",
    "print similarity_scores\n",
    "print sizes\n",
    "print r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def sim(s1,s2):\n",
    "    l = float( max(len(s1),len(s2))) \n",
    "    lp = l - float(levenshtein(s1,s2))\n",
    "    return lp/l \n",
    "\n",
    "\n",
    "print 'testing sim eq', sim(s1[0],s1[0])\n",
    "print 'testing sim dif', sim(s2[0],s1[0])\n",
    "\n",
    "s1=['asdasd','asdasd','abc']\n",
    "s2=['zxczxc','asdasd','abc']\n",
    "\n",
    "\n",
    "def simsum(a,b,del_diag=False):\n",
    "    res=0.0\n",
    "    for i, ea in enumerate(a):\n",
    "        for j, eb in enumerate(b):\n",
    "            if del_diag and i==j:\n",
    "                continue\n",
    "            res+=simmilarity(ea,eb)\n",
    "    return res\n",
    "\n",
    "\n",
    "print 'testing simsum eq',simsum(s1,s1,True)\n",
    "print 'testing simsum neq',simsum(s2,s1)\n",
    "\n",
    "import math\n",
    "def calcsimset(a,b):\n",
    "    print 'calcsimset'\n",
    "    ab=simsum(s1,s2,False)\n",
    "    aa=simsum(a,a,False) \n",
    "    bb=simsum(b,b,False)\n",
    "    print ab,aa,bb\n",
    "    cc=aa*bb\n",
    "    print cc\n",
    "    print ab/math.sqrt(cc)\n",
    "\n",
    "    \n",
    "calcsimset(s1,s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graphlearn import sumsim\n",
    "print sumsim.__file__\n",
    "s1=['asdasd','asdasd','abc']\n",
    "s2=['zxczxc','asdasd','abc']\n",
    "sumsim.calcsimset(s1,s2)\n",
    "sumsim.similarity_mean(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "s1 = [('', 'CUCUUAUUGAGAGCGGUGGAGGGACUGGCCCUGUGAAACCCGGCAACCUUCAAACGAAAUGUUUGAAACGGUGCUAAUACCUGCAAAACGAAUGUUUUGCAUAAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGACAGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGAAAGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGAAACGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'AGCUCAUCCAGAGGGGCAGAGGGAAACGGCCCGAUGAAGCCCCGGCAACCCUCCAGUCGGUACUCGUAGGUCACUGAUUAUGAUAGGGAAGGUGCCAAAUCCGUCUCACGGCGAGAUGCGUCGUGAGGAAGAUGAGGA'), ('', 'UGCUUAUCUAGAGUGGCGGAGGGAAACGGCCCUUUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAUUCCAGACAGAUGAGGA'), ('', 'UUCUUAUCAAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCUUUUGGCAAAAUCUAAGCCUGAAAGAUGAGAA'), ('', 'CUUUUAUCCAGAGAUGGCGGAGGGACAGGCCCGAAGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('', 'CUUUUAUCCAGAGAUGGCGGAGGGAAAGGCCCGAAGAAGCCCAGCAACCUCUUCGUAACGAAGAAAGGUGCCAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('', 'AGCUUAUCGAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCCAUCCCGAAUAUUCGGGAAUAGAUGAGCG')] \n",
    "s2 = [('ACEZ01000126.1/65345-65190', 'AGCUCAUCCAGAGGGGCAGAGGGAAACGGCCCGAUGAAGCCCCGGCAACCCUCCAGUCGGUACUCGUAGGUCACUGGCGACCACUUCGCGAGGCUCCCGACUAGGGAAGGUGCCAAAUCCGUCUCACGGCGAGAUGCGUCGUGAGGAAGAUGAGGA'), ('AP008934.1/1011112-1011223', 'CUCUUAUCCUGAGUGGCGGAGGGACAUGGACCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('AAVL02000036.1/100921-100817', 'CUCUUAUUAAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACGGCAACCCCCGAUUAUGAUGGAAGGUGCCCACCGGAGCAAUGCAAUAUUGAUCAAUAAGAG'), ('AE017225.1/4074580-4074471', 'CUCUUAUUGAGAGCGGUGGAGGGAAAGGCCCUGUGAAACCCGGCAACCUUCAAACGAAAUGUUUGAAACGGUGCUAAUACCUGCAAAACGAAUGUUUUGCAUAAUAAGAG'), ('ABDQ01000003.1/211832-211918', 'UGCUUAUCUAGAGUGGCGGAGGGACUGGCCCUUUGAAGCCCAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCAGACAGAUGAGGA'), ('AP006627.1/3008449-3008342', 'CUUUUAUCCAGAGAUGGCGGAGGGACAGGCCCGAAGAAGCCCAGCAACCAACACGUAACGUGUAAAGGUGCUAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('AAXV01000005.1/126573-126679', 'UUCUUAUCAAGAGAGACGGAGGGAUCGGCCCGAUGAAGUCUCAGCAACCAGCUCAAUCAGUAUGGUGCUAAUUCCUUUUGGCAAAAUCUAAGCCUGAAAGAUGAGAA'), ('AAXU02000001.1/3185191-3185093', 'AGCUUAUCGAGAAAGACUGAGGGAAGGGCCCGACGACGUCUUAGCAACCUGUAACCAAGGUGCUAAUUCCCAUCCCGAAUAUUCGGGAAUAGAUGAGCG')]\n",
    "\n",
    "\n",
    "from Valium import sumsim as ss\n",
    "print ss.__file__\n",
    "#sumsim.calcsimset(s1,s2)\n",
    "#ss.score(s1,s2)\n",
    "a,b = ss.vectorize(s1,s2)\n",
    "dist= ss.compdistr(a,b)\n",
    "print dist\n",
    "sim = ss.simset(a,b)\n",
    "print 'sim',sim\n",
    "print dist-sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datapoint(size):\n",
    "    ra=[]\n",
    "    rb=[]\n",
    "    rab=[]\n",
    "    similarities=[]\n",
    "    global similarity_scores\n",
    "    for rep in range(repeats):\n",
    "\n",
    "\n",
    "        a,b,ab,similarity = evaluate_point(size)\n",
    "        ra.append(a)\n",
    "        rab.append(ab)\n",
    "        rb.append(b)\n",
    "        similarities.append(similarity)\n",
    "        \n",
    "    similarity_scores.append( \n",
    "        (sum(similarities)/float(len(similarities)))\n",
    "        )\n",
    "    return ra,rb,rab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_point(size):\n",
    "    res=[]\n",
    "\n",
    "    train_aa,train_a,test_a = get_trainthings(size,dataset_a)\n",
    "    train_bb,train_b,test_b = get_trainthings(size,dataset_b)\n",
    "\n",
    "\n",
    "    res.append(  \n",
    "        test(deepcopy(train_a),deepcopy(train_b),deepcopy(test_a),deepcopy(test_b)) \n",
    "    )\n",
    "    eins=sumsim.simset(deepcopy(train_aa),deepcopy(train_a))\n",
    "    zwei=sumsim.simset(deepcopy(train_bb),deepcopy(train_b)) \n",
    "    drei = (eins+zwei)/2.0\n",
    "    res.append(  test(deepcopy(train_aa),deepcopy(train_bb),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(  test(deepcopy(train_a)+deepcopy(train_aa),deepcopy(train_b)+train_bb,deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(drei)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means,ng [20 25 30 35 40 45 50] [ 0.98055556  0.99444444  0.98888889  0.975       0.97222222  0.99166667\n",
      "  1.        ]\n",
      "a [  9.86111111e-01   3.47972940e+05]\n",
      "b [[ inf  inf]\n",
      " [ inf  inf]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "means,ng [20 25 30 35 40 45 50] [ 0.95        0.97777778  0.99166667  0.98888889  0.97777778  0.98333333\n",
      "  0.99166667]\n",
      "a [  9.80158730e-01   2.73407536e+05]\n",
      "b [[ inf  inf]\n",
      " [ inf  inf]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "means,ng [20 25 30 35 40 45 50] [ 0.98888889  0.99444444  0.99722222  0.98333333  0.98888889  0.99722222\n",
      "  0.99444444]\n",
      "a [  9.92063492e-01   2.48552402e+05]\n",
      "b [[ inf  inf]\n",
      " [ inf  inf]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[20 25 30 35 40 45 50]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36f6e9cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAFtCAYAAABvHyAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQAApoRFAACmfgGL4oLJzym4qwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36f70d10d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import curve\n",
    "\n",
    "sizes = [20, 25]\n",
    "result = [[[0.95], [1.0]], [[0.975], [0.9]], [[0.95], [1.0]]]\n",
    "\n",
    "sizes = [20, 25]\n",
    "result = [[[1.0, 0.95, 1.0], [1.0, 0.975, 1.0]], [[0.775, 0.775, 0.925], [1.0, 1.0, 0.925]], [[0.975, 0.95, 0.975], [0.875, 0.975, 1.0]]]\n",
    "similarity_scores = [1.0297192402202902, 1.0271841248414073]\n",
    "curve.similarity_scores = similarity_scores \n",
    "\n",
    "result = [\n",
    "            [\n",
    "                [1.0, 1.0, 0.975, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 0.95, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 0.975], \n",
    "                [0.975, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0],\n",
    "                [1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [0.925, 0.95, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975], \n",
    "                [1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0], \n",
    "                [0.975, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0]], \n",
    "            [\n",
    "                [0.825, 1.0, 0.9, 1.0, 0.975, 0.825, 0.725, 0.6, 1.0], \n",
    "                [0.675, 0.9, 0.775, 1.0, 0.85, 1.0, 0.8, 0.85, 0.975], \n",
    "                [1.0, 1.0, 0.975, 0.975, 0.9, 0.975, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0], \n",
    "                [1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0], \n",
    "                [0.975, 0.975, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0], \n",
    "                [1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975]], \n",
    "           [\n",
    "                [0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0], \n",
    "                [1.0, 1.0, 0.95, 0.975, 0.975, 1.0, 0.95, 1.0, 1.0], \n",
    "                [1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0], \n",
    "                [0.975, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "        ]\n",
    "similarity_scores = [1.0232968855718843, 1.0007455908832672, 0.99180448653574027, 0.98595714838649307, 0.9916254516732721, 0.98422063083413702, 0.98257742970417483]\n",
    "\n",
    "result = [[[1.0, 0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0], [0.95, 1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 0.975, 1.0], [1.0, 0.925, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975], [1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975]], [[0.975, 0.975, 1.0, 0.825, 0.925, 0.925, 0.95, 1.0, 0.975], [1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 0.95, 1.0, 0.975], [1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975], [1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0], [0.975, 0.95, 0.975, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975], [1.0, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 0.925], [1.0, 1.0, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 0.975]], [[1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.85, 1.0, 1.0], [1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95], [1.0, 1.0, 0.825, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0], [0.975, 1.0, 0.975, 0.975, 0.875, 1.0, 0.975, 1.0, 0.975], [1.0, 1.0, 1.0, 0.975, 1.0, 0.95, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]]\n",
    "similarity_scores = [1.0168101311663511, 1.0150377354846287, 1.0009668568440384, 1.0013156444262343, 0.99809664727147385, 0.99622003788844737, 0.99512742871661353]\n",
    "curve.similarity_scores=similarity_scores\n",
    "numgr=[20 ,25 ,30, 35, 40, 45, 50]\n",
    "curve.plot2(\"%s vs %s discriminative performance\" % (curve.dataset_a[:-3],curve.dataset_b[:-3]),numgr,*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=np.array(range(4))\n",
    "l.tolist()*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

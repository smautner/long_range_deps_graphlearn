{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import eden\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import Sampler as GraphLearnSampler\n",
    "from eden.util import fit,estimate\n",
    "from eden.path import Vectorizer\n",
    "import random\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "import random\n",
    "'''\n",
    "GET RNA DATA\n",
    "'''\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import itertools\n",
    "\n",
    "def rfam_uri(family_id):\n",
    "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
    "def rfam_uri(family_id):\n",
    "    return '%s.fa'%(family_id)\n",
    " \n",
    "\n",
    "from eden.converter.fasta import fasta_to_sequence\n",
    "def get_sequences_with_names(filename='RF00005.fa'):\n",
    "    sequences = fasta_to_sequence(\"../toolsdata/\"+filename)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_graphs(fname,size):\n",
    "    graphs=[g for g in get_sequences_with_names(fname)]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size]\n",
    "\n",
    "# formerly:\n",
    "#get_graphs(dataset_fname, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "from graphlearn.estimator import Wrapper as estimatorwrapper\n",
    "import graphlearn.utils.draw as draw\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def fit_sample(graphs, random_state=random.random()):\n",
    "    '''\n",
    "    graphs -> more graphs\n",
    "    '''\n",
    "    graphs = list(graphs)\n",
    "    estimator=estimatorwrapper( nu=.5, cv=2, n_jobs=-1)\n",
    "    sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                                thickness_list=[2], \n",
    "                                min_cip_count=1, \n",
    "                                min_interface_count=2, \n",
    "                                preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                                postprocessor=rna.PostProcessor(),\n",
    "                                estimator=estimator\n",
    "                                #feasibility_checker=feasibility\n",
    "                               )\n",
    "    sampler.fit(graphs,grammar_n_jobs=4,grammar_batch_size=1)\n",
    "    \n",
    "    \n",
    "    logger.info('graph grammar stats:')\n",
    "    dataset_size, interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#instances:%d   #interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (dataset_size, interface_counts, core_counts, cip_counts))\n",
    "    \n",
    "    \n",
    "    graphs = [ b for a ,b in graphs  ]\n",
    "    \n",
    "    graphs = sampler.sample(graphs,\n",
    "                            n_samples=3,\n",
    "                            batch_size=1,\n",
    "                            n_steps=50,\n",
    "                            n_jobs=4,\n",
    "                            quick_skip_orig_cip=True,\n",
    "                            probabilistic_core_choice=True,\n",
    "                            burnin=10,\n",
    "                            improving_threshold=0.9,\n",
    "                            improving_linear_start=0.3,\n",
    "                            max_size_diff=20,\n",
    "                            accept_min_similarity=0.65,\n",
    "                            select_cip_max_tries=30,\n",
    "                            keep_duplicates=False,\n",
    "                            include_seed=False,\n",
    "                            backtrack=10,\n",
    "                            monitor=False)\n",
    "    result=[]\n",
    "    for graphlist in graphs:\n",
    "        result+=graphlist\n",
    "    # note that this is a list [('',sequ),..]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(pos_original, neg_original,\n",
    "                     pos_sampled, neg_sampled,\n",
    "                     pos_test, neg_test,\n",
    "                     random_state=42):\n",
    "    '''\n",
    "    pos + neg orig+sampled testsets -> orig_roc , sampled_roc, augmented_roc\n",
    "    '''\n",
    "    \n",
    "    # create graph sets...orig augmented and sampled\n",
    "    pos_orig,pos_orig_ = tee(pos_original)\n",
    "    neg_orig,neg_orig_ = tee(neg_original)\n",
    "    \n",
    "    pos_sampled, pos_sampled_ = tee(pos_sampled)\n",
    "    neg_sampled, neg_sampled_ = tee(neg_sampled)\n",
    "    \n",
    "    pos_augmented = chain(pos_orig_,pos_sampled_)\n",
    "    neg_augmented = chain(neg_orig_,neg_sampled_)\n",
    "\n",
    "    predictive_performances = []\n",
    "    for desc,pos_train,neg_train in [('original',pos_orig, neg_orig),\n",
    "                                     ('sample',pos_sampled,neg_sampled),\n",
    "                                     ('original+sample',pos_augmented, neg_augmented)]:\n",
    "        pos_train,pos_train_ = tee(pos_train)\n",
    "        neg_train,neg_train_ = tee(neg_train)\n",
    "        pos_size=sum(1 for x in pos_train_)\n",
    "        neg_size=sum(1 for x in neg_train_)\n",
    "\n",
    "        logger.info( \"-\"*80)\n",
    "        logger.info('working on %s'%(desc))\n",
    "        logger.info('training set sizes: #pos: %d #neg: %d'%(pos_size, neg_size))\n",
    "\n",
    "        if pos_size == 0 or neg_size == 0:\n",
    "            logger.info('WARNING: empty dataset')\n",
    "            predictive_performances.append(0)            \n",
    "        else:\n",
    "            start=time()\n",
    "            pos_test,pos_test_ = tee(pos_test)\n",
    "            neg_test,neg_test_ = tee(neg_test)\n",
    "            \n",
    "            local_estimator = fit(pos_train, neg_train, Vectorizer(4), n_jobs=-1, n_iter_search=1)\n",
    "            apr, roc = estimate(pos_test_, neg_test_, local_estimator, Vectorizer(4))\n",
    "            predictive_performances.append(roc)\n",
    "            logger.info( 'elapsed: %.1f sec'%(time()-start))\n",
    "    return predictive_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pos_fname, neg_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs_pos = get_graphs(pos_fname, size=size)\n",
    "    graphs_neg = get_graphs(neg_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    pos_train_global,pos_test_global = random_bipartition_iter(graphs_pos,train_test_split,random_state=random.random()*1000)\n",
    "    neg_train_global,neg_test_global = random_bipartition_iter(graphs_neg,train_test_split,random_state=random.random()*1000)\n",
    "\n",
    "\n",
    "    original_repetitions = []\n",
    "    original_sample_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random_state = int(313379*percentage+repetition) \n",
    "            random.seed(random_state)\n",
    "            pos_train_global,pos_train_global_ = tee(pos_train_global)\n",
    "            neg_train_global,neg_train_global_ = tee(neg_train_global)\n",
    "            pos_test_global,pos_test_global_ = tee(pos_test_global)\n",
    "            neg_test_global,neg_test_global_ = tee(neg_test_global)\n",
    "\n",
    "            # use shuffled list to create test and sample set\n",
    "            pos,pos_reminder = random_bipartition_iter(pos_train_global_,percentage)\n",
    "            pos,pos_ = tee(pos)\n",
    "            neg,neg_reminder = random_bipartition_iter(neg_train_global_,percentage)\n",
    "            neg,neg_ = tee(neg)\n",
    "\n",
    "            #sample independently from the 2 classes\n",
    "            logger.info('Positive')\n",
    "            sampled_pos = fit_sample(pos_, random_state=random_state)\n",
    "            logger.info('Negative')\n",
    "            sampled_neg = fit_sample(neg_, random_state=random_state)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            logger.info( \"=\"*80)\n",
    "            logger.info( 'repetition: %d/%d'%(repetition+1, n_repetitions))\n",
    "            logger.info( \"training percentage:\"+str(percentage))\n",
    "            perf_orig,\\\n",
    "            perf_samp,\\\n",
    "            perf_orig_samp = fit_and_evaluate(pos,neg,\n",
    "                                              sampled_pos,sampled_neg,\n",
    "                                              pos_test_global_,neg_test_global_)\n",
    "            logger.info( 'Time elapsed for full repetition: %.1f sec'%((time()-start)))\n",
    "            originals.append(perf_orig)\n",
    "            originals_samples.append(perf_orig_samp)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        original_sample_repetitions.append(originals_samples)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, original_sample_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    FONTSIZE=20\n",
    "    ws = 1\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    ax = plt.subplot() \n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(20)\n",
    "    \n",
    "    \n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original+sample')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.xlim(2,15)\n",
    "    #plt.ylim(0.99,1.005)\n",
    "    plt.ylim(0.0,1.005)\n",
    "    plt.title(dataset+'\\n',fontsize=20)\n",
    "    plt.legend(loc='lower right',fontsize=18)\n",
    "    plt.ylabel('ROC AUC',fontsize=18)\n",
    "    plt.xlabel('Training set size per family',fontsize=18)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)\n",
    "\n",
    "#load(\"DATAS\")\n",
    "#plot(\"RF00162 vs RF00005 learning curve\", percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions):\\n    with open(result_fname,'w') as f:\\n        f.write('dataset sizes list:\\n')\\n        for perc in percentages:\\n            f.write('%s '% perc)\\n        f.write('\\n')\\n        f.write('AUC scores:\\n')\\n        for repetitions in original_repetitions,original_sample_repetitions,sample_repetitions:\\n            f.write('%s\\n' % len(repetitions))\\n            for repetition in repetitions:\\n                for auc in repetition:\\n                    f.write('%s ' % auc)\\n                f.write('\\n')\\n    \\ndef load_results(result_fname):\\n    with open(result_fname) as f:\\n        comment = next(f)\\n        line = next(f)\\n        percentages = [float(x) for x in line.split()]\\n        comment = next(f)\\n\\n        original_repetitions = []\\n        size = int(next(f))\\n        for i in range(size):\\n            line = next(f)\\n            repetition = [float(x) for x in line.split()]\\n            original_repetitions.append(repetition)\\n\\n        original_sample_repetitions = []\\n        size = int(next(f))\\n        for i in range(size):\\n            line = next(f)\\n            repetition = [float(x) for x in line.split()]\\n            original_sample_repetitions.append(repetition)\\n\\n\\n        sample_repetitions = []\\n        size = int(next(f))\\n        for i in range(size):\\n            line = next(f)\\n            repetition = [float(x) for x in line.split()]\\n            sample_repetitions.append(repetition)\\n            \\n    return percentages, original_repetitions,original_sample_repetitions,sample_repetitions\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions):\n",
    "    with open(result_fname,'w') as f:\n",
    "        f.write('dataset sizes list:\\n')\n",
    "        for perc in percentages:\n",
    "            f.write('%s '% perc)\n",
    "        f.write('\\n')\n",
    "        f.write('AUC scores:\\n')\n",
    "        for repetitions in original_repetitions,original_sample_repetitions,sample_repetitions:\n",
    "            f.write('%s\\n' % len(repetitions))\n",
    "            for repetition in repetitions:\n",
    "                for auc in repetition:\n",
    "                    f.write('%s ' % auc)\n",
    "                f.write('\\n')\n",
    "    \n",
    "def load_results(result_fname):\n",
    "    with open(result_fname) as f:\n",
    "        comment = next(f)\n",
    "        line = next(f)\n",
    "        percentages = [float(x) for x in line.split()]\n",
    "        comment = next(f)\n",
    "\n",
    "        original_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_repetitions.append(repetition)\n",
    "\n",
    "        original_sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_sample_repetitions.append(repetition)\n",
    "\n",
    "\n",
    "        sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            sample_repetitions.append(repetition)\n",
    "            \n",
    "    return percentages, original_repetitions,original_sample_repetitions,sample_repetitions\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experimental pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot(\"RF00162 vs RF01725\", percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "\n",
    "#print '%s_predictive_performance_of_samples.data'%dataset\n",
    "#!cat \"RF00162 vs RF00005 training curve_predictive_performance_of_samples.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\n",
    "#plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\n#special case: bursi\\n\\ndataset='RF00162 vs RF00005 training curve'\\n#logging\\nlogger = logging.getLogger()\\nif True:\\n    logger_fname = '%s_predictive_performance_of_samples.log'%dataset\\nelse:\\n    logger_fname = None\\nconfigure_logging(logger,verbosity=1, filename=logger_fname)\\n\\n#main \\nstart=time()\\nprint( 'Working with dataset: %s' % dataset )\\n\\nlogger.info( 'Working with dataset: %s' % dataset )\\npos_dataset_fname = 'RF00005.fa'\\nneg_dataset_fname = 'mixed.fa'\\n\\npos_dataset_fname = 'RF00162.fa'\\nneg_dataset_fname = 'RF01725.fa'\\n\\npercentages=[.08,.2,.4,.6,.8,.95]\\npercentages=[.07,0.1,0.15,0.2]\\npercentages=[.07,.1]\\n\\n\\n# set size to 900 in production\\noriginal_repetitions,original_sample_repetitions,sample_repetitions = evaluate(pos_dataset_fname,\\n                              neg_dataset_fname,\\n                              size=100,\\n                              percentages=percentages,\\n                              n_repetitions=6, # ORIG = 10\\n                              train_test_split=0.7)\\n#save and display results\\nresult_fname='%s_predictive_performance_of_samples.data'%dataset\\nsave_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions) \\n\\n\\npercentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\\nplot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\\n\\nprint('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "#special case: bursi\n",
    "\n",
    "dataset='RF00162 vs RF00005 training curve'\n",
    "#logging\n",
    "logger = logging.getLogger()\n",
    "if True:\n",
    "    logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "else:\n",
    "    logger_fname = None\n",
    "configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "\n",
    "#main \n",
    "start=time()\n",
    "print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "logger.info( 'Working with dataset: %s' % dataset )\n",
    "pos_dataset_fname = 'RF00005.fa'\n",
    "neg_dataset_fname = 'mixed.fa'\n",
    "\n",
    "pos_dataset_fname = 'RF00162.fa'\n",
    "neg_dataset_fname = 'RF01725.fa'\n",
    "\n",
    "percentages=[.08,.2,.4,.6,.8,.95]\n",
    "percentages=[.07,0.1,0.15,0.2]\n",
    "percentages=[.07,.1]\n",
    "\n",
    "\n",
    "# set size to 900 in production\n",
    "original_repetitions,\\\n",
    "original_sample_repetitions,\\\n",
    "sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                              neg_dataset_fname,\n",
    "                              size=100,\n",
    "                              percentages=percentages,\n",
    "                              n_repetitions=6, # ORIG = 10\n",
    "                              train_test_split=0.7)\n",
    "#save and display results\n",
    "result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions) \n",
    "\n",
    "\n",
    "percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results('%s_predictive_performance_of_samples.data'%dataset)\n",
    "plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "\n",
    "print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time\\nfor dataset in dataset_names:\\n    #logging\\n    logger = logging.getLogger()\\n    if True:\\n        logger_fname = \\'%s_predictive_performance_of_samples.log\\'%dataset\\n    else:\\n        logger_fname = None\\n    configure_logging(logger,verbosity=1, filename=logger_fname)\\n    \\n    #main \\n    start=time()\\n    print( \\'Working with dataset: %s\\' % dataset )\\n\\n    logger.info( \\'Working with dataset: %s\\' % dataset )\\n    pos_dataset_fname = \"RF00005.fa\"\\n    neg_dataset_fname = \\'mixed.fa\\n\\n    percentages=[.05,.2,.4,.6,.8,.95]\\n    percentages=[.05,.2]\\n\\n    original_repetitions,    original_sample_repetitions,    sample_repetitions = evaluate(pos_dataset_fname,\\n                                  neg_dataset_fname,\\n                                  size=400,\\n                                  percentages=percentages,\\n                                  n_repetitions=3,\\n                                  train_test_split=0.7)\\n    #save and display results\\n    result_fname=\\'%s_predictive_performance_of_samples.data\\'%dataset\\n    save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions)    \\n    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\\n    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\\n    \\n    print(\\'Time elapsed: %s\\'%(datetime.timedelta(seconds=(time() - start))))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''time\n",
    "for dataset in dataset_names:\n",
    "    #logging\n",
    "    logger = logging.getLogger()\n",
    "    if True:\n",
    "        logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "    else:\n",
    "        logger_fname = None\n",
    "    configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "    \n",
    "    #main \n",
    "    start=time()\n",
    "    print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "    logger.info( 'Working with dataset: %s' % dataset )\n",
    "    pos_dataset_fname = \"RF00005.fa\"\n",
    "    neg_dataset_fname = 'mixed.fa\n",
    "\n",
    "    percentages=[.05,.2,.4,.6,.8,.95]\n",
    "    percentages=[.05,.2]\n",
    "\n",
    "    original_repetitions,\\\n",
    "    original_sample_repetitions,\\\n",
    "    sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                                  neg_dataset_fname,\n",
    "                                  size=400,\n",
    "                                  percentages=percentages,\n",
    "                                  n_repetitions=3,\n",
    "                                  train_test_split=0.7)\n",
    "    #save and display results\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions)    \n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "    \n",
    "    print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor dataset in dataset_names:\\n    result_fname='%s_predictive_performance_of_samples.data'%dataset\\n    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\\n    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "'''\n",
    "for dataset in dataset_names:\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eden.converter.fasta import fasta_to_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "# we always want a test and a train set to omou\n",
    "def get_seq_tups(fname,size,sizeb):\n",
    "    kram = fasta_to_sequence(\"../toolsdata/\"+fname)\n",
    "    graphs=[g for g in kram]\n",
    "    random.shuffle(graphs)\n",
    "    return graphs[:size],graphs[size:size+sizeb]\n",
    "\n",
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions): # note that the var names are not real anymore.\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    FONTSIZE=20\n",
    "    ws = .3\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    ax = plt.subplot() \n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(20)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample+orig')\n",
    "\n",
    "    # testing to plot some dots\n",
    "    global similarity_scores\n",
    "    plt.plot(percentages,similarity_scores,'bo')\n",
    "    \n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.xlim(5,20)\n",
    "    plt.ylim(0.0,1.005)\n",
    "    plt.title(dataset+'\\n',fontsize=20)\n",
    "    plt.legend(loc='lower right',fontsize=18)\n",
    "    plt.ylabel('ROC AUC',fontsize=18)\n",
    "    plt.xlabel('Training set size per family',fontsize=18)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)\n",
    "\n",
    "#load(\"DATAS\")\n",
    "#plot(\"RF00162 vs RF00005 learning curve\", [30,70], [[.30,.30],[.20,.20]] , [[.40,.40],[.30,.30]],[[.70,.35],[.25,.25]])\n",
    "import random\n",
    "import graphlearn.abstract_graphs.RNA as rna\n",
    "from  graphlearn.feasibility import FeasibilityChecker as Checker\n",
    "from graphlearn.estimator import Wrapper as estimatorwrapper\n",
    "import graphlearn.utils.draw as draw\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def fit_sample(graphs, random_state=random.random()):\n",
    "    '''\n",
    "    graphs -> more graphs\n",
    "    '''\n",
    "    graphs = list(graphs)\n",
    "    estimator=estimatorwrapper( nu=.5, cv=2, n_jobs=-1)\n",
    "    sampler=rna.AbstractSampler(radius_list=[0,1],\n",
    "                                thickness_list=[2], \n",
    "                                min_cip_count=1, \n",
    "                                min_interface_count=2, \n",
    "                                preprocessor=rna.PreProcessor(base_thickness_list=[1],ignore_inserts=True), \n",
    "                                postprocessor=rna.PostProcessor(),\n",
    "                                estimator=estimator\n",
    "                                #feasibility_checker=feasibility\n",
    "                               )\n",
    "    sampler.fit(graphs,grammar_n_jobs=4,grammar_batch_size=1)\n",
    "    graphs = [ b for a ,b in graphs  ]\n",
    "    graphs = sampler.sample(graphs,\n",
    "                            n_samples=3,\n",
    "                            batch_size=1,\n",
    "                            n_steps=50,\n",
    "                            n_jobs=4,\n",
    "                            quick_skip_orig_cip=True,\n",
    "                            probabilistic_core_choice=True,\n",
    "                            burnin=10,\n",
    "                            improving_threshold=0.3,\n",
    "                            improving_linear_start=0.2,\n",
    "                            max_size_diff=20,\n",
    "                            accept_min_similarity=0.65,\n",
    "                            select_cip_max_tries=30,\n",
    "                            keep_duplicates=False,\n",
    "                            include_seed=False,\n",
    "                            backtrack=2,\n",
    "                            monitor=False)\n",
    "    result=[]\n",
    "    for graphlist in graphs:\n",
    "        result+=graphlist\n",
    "    # note that this is a list [('',sequ),..]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57605068  1.          0.03300492  0.15936184  0.        ]\n",
      " [ 0.57605068  1.          0.03300492  0.15936184  0.        ]\n",
      " [ 0.03615508  0.03300492  1.          0.          0.05555556]\n",
      " [ 0.12523577  0.15936184  0.          1.          0.        ]\n",
      " [ 0.          0.          0.05555556  0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-17:\n",
      "Process PoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "Process PoolWorker-16:\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    if self._accept(graph_manager, candidate_graph_manager):\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 869, in _sample_multi\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 869, in _sample_multi\n",
      "    return [self._sample(g) for g in graphlist]\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    return [self._sample(g) for g in graphlist]\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 415, in _sample\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 415, in _sample\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 113, in worker\n",
      "    if self._accept(graph_manager, candidate_graph_manager):\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 869, in _sample_multi\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 560, in _accept\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 560, in _accept\n",
      "    return [self._sample(g) for g in graphlist]\n",
      "    score_graph_new = self._score(graphman_new)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 412, in _sample\n",
      "    candidate_graph_manager = self._propose(graph_manager)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 612, in _propose\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 545, in _score\n",
      "    score_graph_new = self._score(graphman_new)\n",
      "    graphman2 = self._propose_graph(graphman)\n",
      "    graphmanager._score= self.estimatorobject.score(graphmanager,keep_vector=self.accept_min_similarity)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 545, in _score\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/estimator.py\", line 115, in score\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.py\", line 655, in _propose_graph\n",
      "    graphmanager._score= self.estimatorobject.score(graphmanager,keep_vector=self.accept_min_similarity)\n",
      "    transformed_graph = self.vectorizer.transform_single(self.unwrap(graphmanager))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/estimator.py\", line 115, in score\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/graph.py\", line 317, in transform_single\n",
      "    transformed_graph = self.vectorizer.transform_single(self.unwrap(graphmanager))\n",
      "    new_graphmanager = self.postprocessor.re_transform_single(new_graph)\n",
      "    return self._convert_dict_to_sparse_matrix(self._transform(0, graph))\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/graph.py\", line 631, in _transform\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/estimator.py\", line 142, in unwrap\n",
      "    self._transform_vertex(graph, v, feature_list)\n",
      "    graph = graphmanager.graph().copy()\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/graph.py\", line 657, in _transform_vertex\n",
      "    self._transform_vertex_pair(graph, vertex_v, vertex_u, distance, feature_list)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 228, in graph\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 28, in re_transform_single\n",
      "    g= nx.disjoint_union(self._base_graph, self.abstract_graph())\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 141, in abstract_graph\n",
      "    return self.pp.re_transform_single(input)\n",
      "    self._abstract_graph = forgi.edge_parent_finder(abstract_graph, self._base_graph)\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/forgi/__init__.py\", line 194, in edge_parent_finder\n",
      "    for n, d in graph.nodes(data=True):\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 93, in re_transform_single\n",
      "KeyboardInterrupt\n",
      "    trans = self.transform([sequence])[0]\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 110, in transform\n",
      "    structure,energy = self.NNmodel.transform_single(('fake',sequence))\n",
      "  File \"/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/abstract_graphs/RNA.py\", line 509, in transform_single\n",
      "    head,seq,stru,en = self.eden_rna_vectorizer._align_sequence_structure(s,neigh,structure_deletions=True)\n",
      "  File \"/home/ikea/nips2016/code/deps/EDeN/eden/RNA.py\", line 176, in _align_sequence_structure\n",
      "    out = sp.check_output(cmd, shell=True)\n",
      "  File \"/usr/lib/python2.7/subprocess.py\", line 567, in check_output\n",
      "    process = Popen(stdout=PIPE, *popenargs, **kwargs)\n",
      "  File \"/usr/lib/python2.7/subprocess.py\", line 711, in __init__\n",
      "    errread, errwrite)\n",
      "  File \"/usr/lib/python2.7/subprocess.py\", line 1235, in _execute_child\n",
      "    self.pid = os.fork()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# calc everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mget_datapoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# transpose , should work OO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'li:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36mget_datapoint\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_seq_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_seq_tups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mrab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5dc645b8ba21>\u001b[0m in \u001b[0;36mevaluate_point\u001b[0;34m(train_a, train_b, test_a, test_b)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtrain_aa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtrain_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0meins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msumsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcsimset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_aa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-8f3286925d44>\u001b[0m in \u001b[0;36mfit_sample\u001b[0;34m(graphs, random_state)\u001b[0m\n\u001b[1;32m     93\u001b[0m                             monitor=False)\n\u001b[1;32m     94\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mgraphlist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mgraphlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# note that this is a list [('',sequ),..]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ikea/nips2016/code/deps/GraphLearn/graphlearn/graphlearn.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, graph_iter, probabilistic_core_choice, score_core_choice, max_size_diff, similarity, n_samples, proposal_probability, batch_size, n_jobs, target_orig_cip, n_steps, quick_skip_orig_cip, improving_threshold, improving_linear_start, accept_static_penalty, accept_min_similarity, select_cip_max_tries, burnin, backtrack, include_seed, keep_duplicates, monitor)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0msampled_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sample_multi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_graphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoni\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mnew_graph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoni\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "#  ok erstmal ueber alle x values, ne\n",
    "size_test=20\n",
    "dataset_a='RF00005.fa'\n",
    "dataset_a='RF01725.fa'\n",
    "dataset_b='RF00162.fa'\n",
    "sizes=[7,8,9,10,11,12,13,14,15]\n",
    "sizes=[7,8]\n",
    "repeats=1\n",
    "\n",
    "# calc everything\n",
    "def get_results():\n",
    "    li = [ get_datapoint(size) for size in sizes ]\n",
    "    # transpose , should work OO \n",
    "    print 'li:',li\n",
    "    return [list(i) for i in zip(*li)]\n",
    "\n",
    "from graphlearn import sumsim\n",
    "# calc for one \"size\", go over repeats\n",
    "def get_datapoint(size):\n",
    "    ra=[]\n",
    "    rb=[]\n",
    "    rab=[]\n",
    "    similarities=[]\n",
    "    global similarity_scores\n",
    "    \n",
    "    for rep in range(repeats):\n",
    "        train_a,test_a = get_seq_tups(dataset_a,size,size_test)\n",
    "        train_b,test_b = get_seq_tups(dataset_b,size,size_test)\n",
    "        a,b,ab,similarity = evaluate_point(train_a,train_b,test_a,test_b)\n",
    "        ra.append(a)\n",
    "        rab.append(ab)\n",
    "        rb.append(b)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    similarity_scores.append( (sum(similarities)/float(len(similarities))))\n",
    "    return ra,rb,rab\n",
    "\n",
    "\n",
    "def evaluate_point(train_a,train_b,test_a,test_b):\n",
    "    res=[]\n",
    "    res.append(  test(deepcopy(train_a),deepcopy(train_b),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    train_aa = fit_sample(train_a)\n",
    "    train_bb = fit_sample(train_b)\n",
    "    \n",
    "    eins=sumsim.calcsimset(deepcopy(train_aa),deepcopy(train_a))   \n",
    "    zwei=sumsim.calcsimset(deepcopy(train_bb),deepcopy(train_b))   \n",
    "    drei = (eins+zwei)/2.0\n",
    "    res.append(  test(deepcopy(train_aa),deepcopy(train_bb),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(  test(deepcopy(train_a)+deepcopy(train_aa),deepcopy(train_b)+train_bb,deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(drei)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "### just evaluate the stuff\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from eden.path import Vectorizer\n",
    "\n",
    "def train_esti(neg,pos):\n",
    "        v=Vectorizer()\n",
    "        matrix=v.transform(neg+pos)\n",
    "        res=SGDClassifier(shuffle=True)\n",
    "        res.fit(matrix, np.asarray(  [-1]*len(neg)+[1]*len(pos)  ) )\n",
    "        return res\n",
    "\n",
    "def eva(esti,ne,po):\n",
    "    v=Vectorizer()\n",
    "    matrix=v.transform(ne)\n",
    "    correct= sum(  [1 for res in esti.predict(matrix) if res == -1] ) \n",
    "    matrix2=v.transform(po)            \n",
    "    correct+= sum(  [1 for res in esti.predict(matrix2) if res == 1] )\n",
    "    return correct\n",
    "\n",
    "def test(a,b,ta,tb):\n",
    "    est=train_esti(a,b)\n",
    "    correct=eva(est,ta,tb)\n",
    "    return correct/float(size_test*2) # fraction correct\n",
    "    \n",
    "\n",
    "global similarity_scores\n",
    "similarity_scores=[]\n",
    "r=get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b39d1de2cda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'somename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "plot('somename', sizes, *r)\n",
    "\n",
    "print similarity_scores\n",
    "print sizes\n",
    "print r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def sim(s1,s2):\n",
    "    l = float( max(len(s1),len(s2))) \n",
    "    lp = l - float(levenshtein(s1,s2))\n",
    "    return lp/l \n",
    "\n",
    "\n",
    "print 'testing sim eq', sim(s1[0],s1[0])\n",
    "print 'testing sim dif', sim(s2[0],s1[0])\n",
    "\n",
    "s1=['asdasd','asdasd','abc']\n",
    "s2=['zxczxc','asdasd','abc']\n",
    "\n",
    "\n",
    "def simsum(a,b,del_diag=False):\n",
    "    res=0.0\n",
    "    for i, ea in enumerate(a):\n",
    "        for j, eb in enumerate(b):\n",
    "            if del_diag and i==j:\n",
    "                continue\n",
    "            res+=simmilarity(ea,eb)\n",
    "    return res\n",
    "\n",
    "\n",
    "print 'testing simsum eq',simsum(s1,s1,True)\n",
    "print 'testing simsum neq',simsum(s2,s1)\n",
    "\n",
    "import math\n",
    "def calcsimset(a,b):\n",
    "    print 'calcsimset'\n",
    "    ab=simsum(s1,s2,False)\n",
    "    aa=simsum(a,a,False) \n",
    "    bb=simsum(b,b,False)\n",
    "    print ab,aa,bb\n",
    "    cc=aa*bb\n",
    "    print cc\n",
    "    print ab/math.sqrt(cc)\n",
    "\n",
    "    \n",
    "calcsimset(s1,s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graphlearn import sumsim\n",
    "print sumsim.__file__\n",
    "s1=['asdasd','asdasd','abc']\n",
    "s2=['zxczxc','asdasd','abc']\n",
    "sumsim.calcsimset(s1,s2)\n",
    "sumsim.similarity_mean(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "s1 = [('', 'CUCUUAUUGAGAGCGGUGGAGGGACUGGCCCUGUGAAACCCGGCAACCUUCAAACGAAAUGUUUGAAACGGUGCUAAUACCUGCAAAACGAAUGUUUUGCAUAAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGACAGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGAAAGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'CUCUUAUCCUGAGUGGCGGAGGGAAACGGCCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('', 'AGCUCAUCCAGAGGGGCAGAGGGAAACGGCCCGAUGAAGCCCCGGCAACCCUCCAGUCGGUACUCGUAGGUCACUGAUUAUGAUAGGGAAGGUGCCAAAUCCGUCUCACGGCGAGAUGCGUCGUGAGGAAGAUGAGGA'), ('', 'UGCUUAUCUAGAGUGGCGGAGGGAAACGGCCCUUUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAUUCCAGACAGAUGAGGA'), ('', 'UUCUUAUCAAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCUUUUGGCAAAAUCUAAGCCUGAAAGAUGAGAA'), ('', 'CUUUUAUCCAGAGAUGGCGGAGGGACAGGCCCGAAGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('', 'CUUUUAUCCAGAGAUGGCGGAGGGAAAGGCCCGAAGAAGCCCAGCAACCUCUUCGUAACGAAGAAAGGUGCCAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('', 'AGCUUAUCGAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCCAUCCCGAAUAUUCGGGAAUAGAUGAGCG')] \n",
    "s2 = [('ACEZ01000126.1/65345-65190', 'AGCUCAUCCAGAGGGGCAGAGGGAAACGGCCCGAUGAAGCCCCGGCAACCCUCCAGUCGGUACUCGUAGGUCACUGGCGACCACUUCGCGAGGCUCCCGACUAGGGAAGGUGCCAAAUCCGUCUCACGGCGAGAUGCGUCGUGAGGAAGAUGAGGA'), ('AP008934.1/1011112-1011223', 'CUCUUAUCCUGAGUGGCGGAGGGACAUGGACCCAAUGAAGCCCAGCAACCUCUUCUUAAUUGAAGAAAGGUGCCAAACCGUUUGCAGACAAAUAGCGUCUGAACGAUAAGAG'), ('AAVL02000036.1/100921-100817', 'CUCUUAUUAAGAGUUGGCGGAGAUACAAGGAUCUGUGAUGCCACGGCAACCCCCGAUUAUGAUGGAAGGUGCCCACCGGAGCAAUGCAAUAUUGAUCAAUAAGAG'), ('AE017225.1/4074580-4074471', 'CUCUUAUUGAGAGCGGUGGAGGGAAAGGCCCUGUGAAACCCGGCAACCUUCAAACGAAAUGUUUGAAACGGUGCUAAUACCUGCAAAACGAAUGUUUUGCAUAAUAAGAG'), ('ABDQ01000003.1/211832-211918', 'UGCUUAUCUAGAGUGGCGGAGGGACUGGCCCUUUGAAGCCCAGCAACCUAUAUUUAUUAUGUGGUGCUAAUUCCAGACAGAUGAGGA'), ('AP006627.1/3008449-3008342', 'CUUUUAUCCAGAGAUGGCGGAGGGACAGGCCCGAAGAAGCCCAGCAACCAACACGUAACGUGUAAAGGUGCUAACCUGCAGAAUGCUCGGCGUUCUGGAAGAUAAGAG'), ('AAXV01000005.1/126573-126679', 'UUCUUAUCAAGAGAGACGGAGGGAUCGGCCCGAUGAAGUCUCAGCAACCAGCUCAAUCAGUAUGGUGCUAAUUCCUUUUGGCAAAAUCUAAGCCUGAAAGAUGAGAA'), ('AAXU02000001.1/3185191-3185093', 'AGCUUAUCGAGAAAGACUGAGGGAAGGGCCCGACGACGUCUUAGCAACCUGUAACCAAGGUGCUAAUUCCCAUCCCGAAUAUUCGGGAAUAGAUGAGCG')]\n",
    "\n",
    "\n",
    "from Valium import sumsim as ss\n",
    "print ss.__file__\n",
    "#sumsim.calcsimset(s1,s2)\n",
    "#ss.score(s1,s2)\n",
    "a,b = ss.vectorize(s1,s2)\n",
    "dist= ss.compdistr(a,b)\n",
    "print dist\n",
    "sim = ss.simset(a,b)\n",
    "print 'sim',sim\n",
    "print dist-sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datapoint(size):\n",
    "    ra=[]\n",
    "    rb=[]\n",
    "    rab=[]\n",
    "    similarities=[]\n",
    "    global similarity_scores\n",
    "    for rep in range(repeats):\n",
    "\n",
    "\n",
    "        a,b,ab,similarity = evaluate_point(size)\n",
    "        ra.append(a)\n",
    "        rab.append(ab)\n",
    "        rb.append(b)\n",
    "        similarities.append(similarity)\n",
    "        \n",
    "    similarity_scores.append( \n",
    "        (sum(similarities)/float(len(similarities)))\n",
    "        )\n",
    "    return ra,rb,rab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_point(size):\n",
    "    res=[]\n",
    "\n",
    "    train_aa,train_a,test_a = get_trainthings(size,dataset_a)\n",
    "    train_bb,train_b,test_b = get_trainthings(size,dataset_b)\n",
    "\n",
    "\n",
    "    res.append(  \n",
    "        test(deepcopy(train_a),deepcopy(train_b),deepcopy(test_a),deepcopy(test_b)) \n",
    "    )\n",
    "    eins=sumsim.simset(deepcopy(train_aa),deepcopy(train_a))\n",
    "    zwei=sumsim.simset(deepcopy(train_bb),deepcopy(train_b)) \n",
    "    drei = (eins+zwei)/2.0\n",
    "    res.append(  test(deepcopy(train_aa),deepcopy(train_bb),deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(  test(deepcopy(train_a)+deepcopy(train_aa),deepcopy(train_b)+train_bb,deepcopy(test_a),deepcopy(test_b)) )\n",
    "    res.append(drei)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 30]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f416fbdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAEICAYAAAAJGW4GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f41703350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import curve\n",
    "\n",
    "sizes = [20, 25]\n",
    "result = [[[0.95], [1.0]], [[0.975], [0.9]], [[0.95], [1.0]]]\n",
    "\n",
    "sizes = [20, 25]\n",
    "result = [[[1.0, 0.95, 1.0], [1.0, 0.975, 1.0]], [[0.775, 0.775, 0.925], [1.0, 1.0, 0.925]], [[0.975, 0.95, 0.975], [0.875, 0.975, 1.0]]]\n",
    "similarity_scores = [1.0297192402202902, 1.0271841248414073]\n",
    "curve.similarity_scores = similarity_scores \n",
    "\n",
    "result = [\n",
    "            [\n",
    "                [1.0, 1.0, 0.975, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 0.95, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 0.975], \n",
    "                [0.975, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0],\n",
    "                [1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [0.925, 0.95, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975], \n",
    "                [1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0], \n",
    "                [0.975, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0]], \n",
    "            [\n",
    "                [0.825, 1.0, 0.9, 1.0, 0.975, 0.825, 0.725, 0.6, 1.0], \n",
    "                [0.675, 0.9, 0.775, 1.0, 0.85, 1.0, 0.8, 0.85, 0.975], \n",
    "                [1.0, 1.0, 0.975, 0.975, 0.9, 0.975, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0], \n",
    "                [1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0], \n",
    "                [0.975, 0.975, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0], \n",
    "                [1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975]], \n",
    "           [\n",
    "                [0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0], \n",
    "                [1.0, 1.0, 0.95, 0.975, 0.975, 1.0, 0.95, 1.0, 1.0], \n",
    "                [1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0], \n",
    "                [0.975, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "        ]\n",
    "similarity_scores = [1.0232968855718843, 1.0007455908832672, 0.99180448653574027, 0.98595714838649307, 0.9916254516732721, 0.98422063083413702, 0.98257742970417483]\n",
    "\n",
    "result = [[[1.0, 0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0], [0.95, 1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 0.975, 1.0], [1.0, 0.925, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975], [1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975]], [[0.975, 0.975, 1.0, 0.825, 0.925, 0.925, 0.95, 1.0, 0.975], [1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 0.95, 1.0, 0.975], [1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975], [1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0], [0.975, 0.95, 0.975, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975], [1.0, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 0.925], [1.0, 1.0, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 0.975]], [[1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.85, 1.0, 1.0], [1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95], [1.0, 1.0, 0.825, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0], [0.975, 1.0, 0.975, 0.975, 0.875, 1.0, 0.975, 1.0, 0.975], [1.0, 1.0, 1.0, 0.975, 1.0, 0.95, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]]\n",
    "similarity_scores = [1.0168101311663511, 1.0150377354846287, 1.0009668568440384, 1.0013156444262343, 0.99809664727147385, 0.99622003788844737, 0.99512742871661353]\n",
    "\n",
    "numgr=[20 ,25 ,30, 35, 40, 45, 50]\n",
    "\n",
    "result = [[[1.0, 1.0, 0.99], [1.0, 1.0, 1.0]], [[1.0, 0.96, 0.99], [0.98, 1.0, 0.97]], [[1.0, 1.0, 1.0], [1.0, 1.0, 0.99]]]\n",
    "similarity_scores = [0.99824512216575856, 0.99945105815278767]\n",
    "numgr=[20,30]\n",
    "curve.similarity_scores=similarity_scores\n",
    "curve.plot(\"%s vs %s discriminative performance\" % (curve.dataset_a[:-3],curve.dataset_b[:-3]),numgr,*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=np.array(range(4))\n",
    "l.tolist()*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
